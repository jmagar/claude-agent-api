AGENTS.md: Top Safety Rules That Your AI Assistant OpenClaw ...
  URL: https://alirezarezvani.medium.com/agents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c
  ... memory files and skills for production deployment. For working ... structure, 8 autonomous skills, and 19 slash commands that saved my…

  --- Content ---
  [Sitemap](https://alirezarezvani.medium.com/sitemap/sitemap.xml)
  
  [Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&referrer=utm_source%3DmobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)
  
  Sign up
  
  [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
  
  [Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)
  
  [Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)
  
  [Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)
  
  Sign up
  
  [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
  
  ![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)
  
  Member-only story
  
  AGENTS.md: Top Safety Rules That Your AI Assistant OpenClaw Need
  ================================================================
  
  Stop Your OpenClaw (Moltbot / ClawdBot) From Becoming a Security Nightmare: The AGENTS.md Guide
  -----------------------------------------------------------------------------------------------
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:64:64/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---byline--d50f95ce9e7c---------------------------------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---byline--d50f95ce9e7c---------------------------------------)
  
  Follow
  
  9 min read
  
  ·
  
  1 day ago
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fd50f95ce9e7c&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&user=Reza+Rezvani&userId=b66488794c91&source=---header_actions--d50f95ce9e7c---------------------clap_footer------------------)
  
  12
  
  2
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd50f95ce9e7c&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&source=---header_actions--d50f95ce9e7c---------------------bookmark_footer------------------)
  
  [Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Dd50f95ce9e7c&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&source=---header_actions--d50f95ce9e7c---------------------post_audio_button------------------)
  
  Share
  
  Security researchers found hundreds of exposed OpenClaw dashboards in late January 2026. Eight had zero authentication — anyone could send commands, view conversation histories, and steal API keys. The common thread wasn’t sophisticated hacking. It was missing AGENTS.md configuration.
  
  Press enter or click to view image in full size
  
  ![](https://miro.medium.com/v2/resize:fit:700/1*xoihAi4ARUUGUyrtF8TSPA.png)
  
  Safety and Security Best Practices for OpenClaw | Image Generated with Gemini 3 Pro ©
  
  _Note: AI tools assisted with research on this topic. The security analysis, recommendations, and conclusions are entirely my own._
  
  In [Part 1](https://medium.com/@alirezarezvani/10-soul-md-practical-cases-in-a-guide-for-moltbot-clawdbot-defining-who-your-ai-chooses-to-be-dadff9b08fe2)
   of this series, I covered _SOUL.md_ — who your AI chooses to be. [Part 2](https://medium.com/@alirezarezvani/openclaw-moltbot-identity-md-how-i-built-professional-ai-personas-that-actually-work-c964a44001ab)
   explored _IDENTITY.md_ — the persona your AI presents. But personality without boundaries is a liability.
  
  **AGENTS.md is where you define operational safety:** what your AI can do, what requires confirmation, and what it should never attempt. It’s the difference between a helpful assistant and what Cisco called “an absolute security nightmare.”
  
  The January 2026 Wake-Up Call
  -----------------------------
  
  The security community’s response to OpenClaw has been swift and alarming.
  
  Jamieson O’Reilly, founder of red-teaming company Dvuln, ran Shodan scans and…
  
  Create an account to read the full story.
  
  
  ---------------------------------------------
  
  The author made this story available to Medium members only.  
  If you’re new to Medium, create a new account to read this story on us.
  
  [Continue in app](https://play.google.com/store/apps/details?id=com.medium.reader&referrer=utm_source%3Dregwall&source=-----d50f95ce9e7c---------------------post_regwall------------------)
  
  Or, continue in mobile web
  
  [Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c%3Fsource%3D-----d50f95ce9e7c---------------------post_regwall------------------%26skipOnboarding%3D1%7Cregister&source=-----d50f95ce9e7c---------------------post_regwall------------------)
  
  [Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c%3Fsource%3D-----d50f95ce9e7c---------------------post_regwall------------------%26skipOnboarding%3D1%7Cregister&source=-----d50f95ce9e7c---------------------post_regwall------------------)
  
  Sign up with email
  
  Already have an account? [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&source=-----d50f95ce9e7c---------------------post_regwall------------------)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:96:96/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---post_author_info--d50f95ce9e7c---------------------------------------)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:128:128/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---post_author_info--d50f95ce9e7c---------------------------------------)
  
  Follow
  
  [Written by Reza Rezvani\
  -----------------------](https://alirezarezvani.medium.com/?source=post_page---post_author_info--d50f95ce9e7c---------------------------------------)
  
  [3K followers](https://alirezarezvani.medium.com/followers?source=post_page---post_author_info--d50f95ce9e7c---------------------------------------)
  
  ·[77 following](https://alirezarezvani.medium.com/following?source=post_page---post_author_info--d50f95ce9e7c---------------------------------------)
  
  As CTO of a Berlin AI MedTech startup, I tackle daily challenges in healthcare tech. With 2 decades in tech, I drive innovations in human motion analysis.
  
  Follow
  
  Responses (2)
  -------------
  
  [](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--d50f95ce9e7c---------------------------------------)
  
  ![](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)
  
  Write a response
  
  [What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fagents-md-top-safety-rules-that-your-ai-assistant-openclaw-need-d50f95ce9e7c&source=---post_responses--d50f95ce9e7c---------------------respond_sidebar------------------)
  
  Cancel
  
  Respond
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:32:32/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---post_responses--d50f95ce9e7c----0-----------------------------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---post_responses--d50f95ce9e7c----0-----------------------------------)
  
  Author
  
  [1 day ago](https://alirezarezvani.medium.com/the-hardest-part-of-writing-this-was-balancing-capability-with-safety-9f33a5ebb1fb?source=post_page---post_responses--d50f95ce9e7c----0-----------------------------------)
  
  The hardest part of writing this was balancing capability with safety.  
    
  Too strict → useless assistant. Too permissive → security nightmare.  
    
  What safety patterns have worked for your own AI agents? I'm especially interested in prompt injection mitigations you've tested in production.
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F9f33a5ebb1fb&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fthe-hardest-part-of-writing-this-was-balancing-capability-with-safety-9f33a5ebb1fb&user=Reza+Rezvani&userId=b66488794c91&source=---post_responses--9f33a5ebb1fb----0-----------------respond_sidebar------------------)
  
  \--
  
  Reply
  
  [![DrG Second Account](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)](https://medium.com/@briang1621?source=post_page---post_responses--d50f95ce9e7c----1-----------------------------------)
  
  [DrG Second Account](https://medium.com/@briang1621?source=post_page---post_responses--d50f95ce9e7c----1-----------------------------------)
  
  [1 day ago](https://medium.com/@briang1621/thanks-this-is-very-much-needed-0889049c6f2e?source=post_page---post_responses--d50f95ce9e7c----1-----------------------------------)
  
  Thanks, this is very much needed! I’ve been writing security files with rules that load into each session for Claude Code for eight months now. Very necessary, but I’m sure OpenClaw will figure out a way to ignore these Agents.md file shortly, that…more
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F0889049c6f2e&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40briang1621%2Fthanks-this-is-very-much-needed-0889049c6f2e&user=DrG+Second+Account&userId=3bb36567b9a8&source=---post_responses--0889049c6f2e----1-----------------respond_sidebar------------------)
  
  \--
  
  1 reply
  
  Reply
  
  More from Reza Rezvani
  ----------------------
  
  ![How to avoid mistakes with CLAUDE.md](https://miro.medium.com/v2/resize:fit:679/format:webp/1*IRJMOu0mbNgSChGfTBQpUg.png)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:20:20/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----0---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----0---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [### Boris Cherny’s file is 2.5k tokens. Mine was 15k. After 3 weeks studying his workflow, I found the patterns most developers miss — and how…](https://alirezarezvani.medium.com/your-claude-md-is-probably-wrong-7-mistakes-boris-cherny-never-makes-6d3e5e41f4b7?source=post_page---author_recirc--d50f95ce9e7c----0---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  Jan 23
  
  [A response icon18](https://alirezarezvani.medium.com/your-claude-md-is-probably-wrong-7-mistakes-boris-cherny-never-makes-6d3e5e41f4b7?source=post_page---author_recirc--d50f95ce9e7c----0---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d3e5e41f4b7&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fyour-claude-md-is-probably-wrong-7-mistakes-boris-cherny-never-makes-6d3e5e41f4b7&source=---author_recirc--d50f95ce9e7c----0-----------------bookmark_preview----2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  ![Claude Code 2.1 — New Major Features that save development time](https://miro.medium.com/v2/resize:fit:679/format:webp/1*SBfIGgoEAybf3l6xCNC5GA.png)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:20:20/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----1---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----1---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [### Hot reload, hooks frontmatter, wildcard permissions, and context fork — after a week of real testing, here’s what 2.1’s infrastructure…](https://alirezarezvani.medium.com/these-4-claude-code-2-1-features-save-me-at-least-50-minutes-daily-95-developers-skip-them-46d2d10f03cc?source=post_page---author_recirc--d50f95ce9e7c----1---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  Jan 12
  
  [A response icon7](https://alirezarezvani.medium.com/these-4-claude-code-2-1-features-save-me-at-least-50-minutes-daily-95-developers-skip-them-46d2d10f03cc?source=post_page---author_recirc--d50f95ce9e7c----1---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46d2d10f03cc&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Fthese-4-claude-code-2-1-features-save-me-at-least-50-minutes-daily-95-developers-skip-them-46d2d10f03cc&source=---author_recirc--d50f95ce9e7c----1-----------------bookmark_preview----2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  ![Agent Skill Autonomy Levels in Claude Code](https://miro.medium.com/v2/resize:fit:679/format:webp/1*OOx5M7WUCHcYdQlhP1owwg.png)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:20:20/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----2---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----2---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [### After 6 months building agents in production, here’s the 10-team structure, 8 autonomous skills, and 19 slash commands that saved my…](https://alirezarezvani.medium.com/141-claude-code-agents-the-setup-that-actually-works-a-complete-guide-98c2c79bf867?source=post_page---author_recirc--d50f95ce9e7c----2---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  Jan 25
  
  [A response icon7](https://alirezarezvani.medium.com/141-claude-code-agents-the-setup-that-actually-works-a-complete-guide-98c2c79bf867?source=post_page---author_recirc--d50f95ce9e7c----2---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98c2c79bf867&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2F141-claude-code-agents-the-setup-that-actually-works-a-complete-guide-98c2c79bf867&source=---author_recirc--d50f95ce9e7c----2-----------------bookmark_preview----2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  ![Most Powerfull Claude Code Commands Open Source Library](https://miro.medium.com/v2/resize:fit:679/format:webp/1*miIEfGtOsp519QLZjF4P5w.png)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:20:20/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----3---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c----3---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [### Custom slash commands, subagents, and automation workflows that transformed my team’s productivity — with copy-paste templates you can use](https://alirezarezvani.medium.com/10-claude-code-commands-that-cut-my-dev-time-60-a-practical-guide-60036faed17f?source=post_page---author_recirc--d50f95ce9e7c----3---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  Nov 20, 2025
  
  [A response icon26](https://alirezarezvani.medium.com/10-claude-code-commands-that-cut-my-dev-time-60-a-practical-guide-60036faed17f?source=post_page---author_recirc--d50f95ce9e7c----3---------------------2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F60036faed17f&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2F10-claude-code-commands-that-cut-my-dev-time-60-a-practical-guide-60036faed17f&source=---author_recirc--d50f95ce9e7c----3-----------------bookmark_preview----2283fce0_cfcc_40a2_b72c_7e4b0150d0e8--------------)
  
  [See all from Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---author_recirc--d50f95ce9e7c---------------------------------------)
  
  Recommended from Medium
  -----------------------
  
  ![kimi 2.5 claude code](https://miro.medium.com/v2/resize:fit:679/format:webp/1*JXocFYMLz7EVWSPRaOpH3g.png)
  
  [![Joe Njenga](https://miro.medium.com/v2/resize:fill:20:20/1*0Hoc7r7_ybnOvk1t8yR3_A.jpeg)](https://medium.com/@joe.njenga?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [Joe Njenga](https://medium.com/@joe.njenga?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [### Moonshot AI never stops surprising us —  Kimi K2.5 is out, so I paired it with Claude Code, but using Ollama.](https://medium.com/@joe.njenga/i-tested-kimi-k2-5-with-claude-code-1-trillion-parameters-8x-cheaper-than-opus-8d4f9e9c7b4d?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  4d ago
  
  [A response icon9](https://medium.com/@joe.njenga/i-tested-kimi-k2-5-with-claude-code-1-trillion-parameters-8x-cheaper-than-opus-8d4f9e9c7b4d?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d4f9e9c7b4d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40joe.njenga%2Fi-tested-kimi-k2-5-with-claude-code-1-trillion-parameters-8x-cheaper-than-opus-8d4f9e9c7b4d&source=---read_next_recirc--d50f95ce9e7c----0-----------------bookmark_preview----9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  ![Moltbot (Clawdbot) The most hyped AI Assistant Full Guide](https://miro.medium.com/v2/resize:fit:679/format:webp/1*MIwggS9uYbDt-nB19-hW8A.png)
  
  [![Reza Rezvani](https://miro.medium.com/v2/resize:fill:20:20/1*jDxVaEgUePd76Bw8xJrr2g.png)](https://alirezarezvani.medium.com/?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [Reza Rezvani](https://alirezarezvani.medium.com/?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [### What actually works, what doesn’t, and whether you should set this AI Assistant up](https://alirezarezvani.medium.com/everyones-installing-moltbot-clawdbot-here-s-why-i-m-not-running-it-in-production-yet-04f9ec596ef5?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  5d ago
  
  [A response icon8](https://alirezarezvani.medium.com/everyones-installing-moltbot-clawdbot-here-s-why-i-m-not-running-it-in-production-yet-04f9ec596ef5?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F04f9ec596ef5&operation=register&redirect=https%3A%2F%2Falirezarezvani.medium.com%2Feveryones-installing-moltbot-clawdbot-here-s-why-i-m-not-running-it-in-production-yet-04f9ec596ef5&source=---read_next_recirc--d50f95ce9e7c----1-----------------bookmark_preview----9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  ![Local LLMs That Can Replace Claude Code](https://miro.medium.com/v2/resize:fit:679/format:webp/0*JpX_vOrpLzFhJfJM.png)
  
  [![Agent Native](https://miro.medium.com/v2/resize:fill:20:20/1*aZiyRsTwMmjG54EApMtwsg.jpeg)](https://agentnativedev.medium.com/?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [Agent Native](https://agentnativedev.medium.com/?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [### Small team of engineers can easily burn >$2K/mo on Anthropic’s Claude Code (Sonnet/Opus 4.5). As budgets are tight, you might be wondering…](https://agentnativedev.medium.com/local-llms-that-can-replace-claude-code-6f5b6cac93bf?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  Jan 20
  
  [A response icon13](https://agentnativedev.medium.com/local-llms-that-can-replace-claude-code-6f5b6cac93bf?source=post_page---read_next_recirc--d50f95ce9e7c----0---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f5b6cac93bf&operation=register&redirect=https%3A%2F%2Fagentnativedev.medium.com%2Flocal-llms-that-can-replace-claude-code-6f5b6cac93bf&source=---read_next_recirc--d50f95ce9e7c----0-----------------bookmark_preview----9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  ![Run Claude Code Locally on Apple Silicon Using LM Studio and LiteLLM (Zero Cost)](https://miro.medium.com/v2/resize:fit:679/format:webp/1*VbfogaijaYX-N7TkoxSElg.jpeg)
  
  [![Data Science Collective](https://miro.medium.com/v2/resize:fill:20:20/1*0nV0Q-FBHj94Kggq00pG2Q.jpeg)](https://medium.com/data-science-collective?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  In
  
  [Data Science Collective](https://medium.com/data-science-collective?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  by
  
  [Manjunath Janardhan](https://medium.com/@manjunath.shiva?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [### A step-by-step guide to running Claude Code with Qwen3-Coder-30B using MLX models on macOS](https://medium.com/@manjunath.shiva/run-claude-code-locally-on-apple-silicon-using-lm-studio-and-litellm-zero-cost-1416a6b984af?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  Jan 21
  
  [A response icon4](https://medium.com/@manjunath.shiva/run-claude-code-locally-on-apple-silicon-using-lm-studio-and-litellm-zero-cost-1416a6b984af?source=post_page---read_next_recirc--d50f95ce9e7c----1---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1416a6b984af&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2Frun-claude-code-locally-on-apple-silicon-using-lm-studio-and-litellm-zero-cost-1416a6b984af&source=---read_next_recirc--d50f95ce9e7c----1-----------------bookmark_preview----9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  ![How Agent Skills Became AI’s Most Important Standard in 90 Days](https://miro.medium.com/v2/resize:fit:679/format:webp/1*VqPChBhF5Apow495dgruIQ.png)
  
  [![AI Advances](https://miro.medium.com/v2/resize:fill:20:20/1*R8zEd59FDf0l8Re94ImV0Q.png)](https://ai.gopubby.com/?source=post_page---read_next_recirc--d50f95ce9e7c----2---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  In
  
  [AI Advances](https://ai.gopubby.com/?source=post_page---read_next_recirc--d50f95ce9e7c----2---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  by
  
  [Han HELOIR YAN, Ph.D. ☕️](https://medium.com/@han.heloir?source=post_page---read_next_recirc--d50f95ce9e7c----2---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [### The AI infrastructure War You Missed](https://medium.com/@han.heloir/how-agent-skills-became-ais-most-important-standard-in-90-days-a66b6369b1b7?source=post_page---read_next_recirc--d50f95ce9e7c----2---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  Jan 25
  
  [A response icon15](https://medium.com/@han.heloir/how-agent-skills-became-ais-most-important-standard-in-90-days-a66b6369b1b7?source=post_page---read_next_recirc--d50f95ce9e7c----2---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa66b6369b1b7&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fhow-agent-skills-became-ais-most-important-standard-in-90-days-a66b6369b1b7&source=---read_next_recirc--d50f95ce9e7c----2-----------------bookmark_preview----9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  ![How to Set Up Clawdbot — Step by Step guide to setup a personal bot](https://miro.medium.com/v2/resize:fit:679/format:webp/1*FQg5JLh5-AIM6G1Znr-qxw.png)
  
  [![Neural Notions](https://miro.medium.com/v2/resize:fill:20:20/1*Xv_4SeKtNfCiqRNi_wDAoA.png)](https://medium.com/modelmind?source=post_page---read_next_recirc--d50f95ce9e7c----3---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  In
  
  [Neural Notions](https://medium.com/modelmind?source=post_page---read_next_recirc--d50f95ce9e7c----3---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  by
  
  [Nikhil](https://nkwrites.medium.com/?source=post_page---read_next_recirc--d50f95ce9e7c----3---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [### Turn your own device into a personal AI assistant that lives inside your favorite apps](https://nkwrites.medium.com/how-to-set-up-clawdbot-step-by-step-guide-to-setup-a-personal-bot-3e7957ed2975?source=post_page---read_next_recirc--d50f95ce9e7c----3---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  Jan 25
  
  [A response icon5](https://nkwrites.medium.com/how-to-set-up-clawdbot-step-by-step-guide-to-setup-a-personal-bot-3e7957ed2975?source=post_page---read_next_recirc--d50f95ce9e7c----3---------------------9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3e7957ed2975&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmodelmind%2Fhow-to-set-up-clawdbot-step-by-step-guide-to-setup-a-personal-bot-3e7957ed2975&source=---read_next_recirc--d50f95ce9e7c----3-----------------bookmark_preview----9c8eee82_2131_458a_8679_37fad2bf1013--------------)
  
  [See more recommendations](https://medium.com/?source=post_page---read_next_recirc--d50f95ce9e7c---------------------------------------)
  
  [Help](https://help.medium.com/hc/en-us?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Status](https://status.medium.com/?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [About](https://medium.com/about?autoplay=1&source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Press](mailto:pressinquiries@medium.com)
  
  [Blog](https://blog.medium.com/?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d50f95ce9e7c---------------------------------------)
  
  [Text to speech](https://speechify.com/medium?source=post_page-----d50f95ce9e7c---------------------------------------)
  --- End Content ---

Memory - OpenClaw
  URL: https://docs.openclaw.ai/experiments/research/memory
  This doc proposes an offline-first memory architecture that keeps Markdown as the canonical, reviewable source of truth, but adds structured recall (search, entity summaries, confidence updates) via a derived index.

  --- Content ---
  [Skip to main content](https://docs.openclaw.ai/experiments/research/memory#content-area)
  
  [OpenClaw home page![light logo](https://mintcdn.com/clawdhub/4rYvG-uuZrMK_URE/assets/pixel-lobster.svg?fit=max&auto=format&n=4rYvG-uuZrMK_URE&q=85&s=da2032e9eac3b5d9bfe7eb96ca6a8a26)![dark logo](https://mintcdn.com/clawdhub/4rYvG-uuZrMK_URE/assets/pixel-lobster.svg?fit=max&auto=format&n=4rYvG-uuZrMK_URE&q=85&s=da2032e9eac3b5d9bfe7eb96ca6a8a26)](https://docs.openclaw.ai/)
  
  ![US](https://d3gk2c5xim1je2.cloudfront.net/flags/US.svg)
  
  English
  
  Search...
  
  Ctrl K
  
  Search...
  
  Navigation
  
  Workspace Memory Research
  
  On this page
  
  *   [Workspace Memory v2 (offline): research notes](https://docs.openclaw.ai/experiments/research/memory#workspace-memory-v2-offline-%3A-research-notes)
      
  *   [Why change?](https://docs.openclaw.ai/experiments/research/memory#why-change)
      
  *   [Design goals](https://docs.openclaw.ai/experiments/research/memory#design-goals)
      
  *   [North star model (Hindsight × Letta)](https://docs.openclaw.ai/experiments/research/memory#north-star-model-hindsight-%C3%97-letta)
      
  *   [Proposed architecture (Markdown source-of-truth + derived index)](https://docs.openclaw.ai/experiments/research/memory#proposed-architecture-markdown-source-of-truth-%2B-derived-index)
      
  *   [Canonical store (git-friendly)](https://docs.openclaw.ai/experiments/research/memory#canonical-store-git-friendly)
      
  *   [Derived store (machine recall)](https://docs.openclaw.ai/experiments/research/memory#derived-store-machine-recall)
      
  *   [Retain / Recall / Reflect (operational loop)](https://docs.openclaw.ai/experiments/research/memory#retain-%2F-recall-%2F-reflect-operational-loop)
      
  *   [Retain: normalize daily logs into “facts”](https://docs.openclaw.ai/experiments/research/memory#retain%3A-normalize-daily-logs-into-%E2%80%9Cfacts%E2%80%9D)
      
  *   [Recall: queries over the derived index](https://docs.openclaw.ai/experiments/research/memory#recall%3A-queries-over-the-derived-index)
      
  *   [Reflect: produce stable pages + update beliefs](https://docs.openclaw.ai/experiments/research/memory#reflect%3A-produce-stable-pages-%2B-update-beliefs)
      
  *   [CLI integration: standalone vs deep integration](https://docs.openclaw.ai/experiments/research/memory#cli-integration%3A-standalone-vs-deep-integration)
      
  *   [Why integrate into OpenClaw?](https://docs.openclaw.ai/experiments/research/memory#why-integrate-into-openclaw)
      
  *   [Why still split a library?](https://docs.openclaw.ai/experiments/research/memory#why-still-split-a-library)
      
  *   [“S-Collide” / SuCo: when to use it (research)](https://docs.openclaw.ai/experiments/research/memory#%E2%80%9Cs-collide%E2%80%9D-%2F-suco%3A-when-to-use-it-research)
      
  *   [Smallest useful pilot](https://docs.openclaw.ai/experiments/research/memory#smallest-useful-pilot)
      
  *   [References](https://docs.openclaw.ai/experiments/research/memory#references)
      
  
  [​](https://docs.openclaw.ai/experiments/research/memory#workspace-memory-v2-offline-:-research-notes)
  
  Workspace Memory v2 (offline): research notes
  =======================================================================================================================================================
  
  Target: Clawd-style workspace (`agents.defaults.workspace`, default `~/.openclaw/workspace`) where “memory” is stored as one Markdown file per day (`memory/YYYY-MM-DD.md`) plus a small set of stable files (e.g. `memory.md`, `SOUL.md`). This doc proposes an **offline-first** memory architecture that keeps Markdown as the canonical, reviewable source of truth, but adds **structured recall** (search, entity summaries, confidence updates) via a derived index.
  
  [​](https://docs.openclaw.ai/experiments/research/memory#why-change)
  
  Why change?
  -----------------------------------------------------------------------------------
  
  The current setup (one file per day) is excellent for:
  
  *   “append-only” journaling
  *   human editing
  *   git-backed durability + auditability
  *   low-friction capture (“just write it down”)
  
  It’s weak for:
  
  *   high-recall retrieval (“what did we decide about X?”, “last time we tried Y?”)
  *   entity-centric answers (“tell me about Alice / The Castle / warelay”) without rereading many files
  *   opinion/preference stability (and evidence when it changes)
  *   time constraints (“what was true during Nov 2025?”) and conflict resolution
  
  [​](https://docs.openclaw.ai/experiments/research/memory#design-goals)
  
  Design goals
  --------------------------------------------------------------------------------------
  
  *   **Offline**: works without network; can run on laptop/Castle; no cloud dependency.
  *   **Explainable**: retrieved items should be attributable (file + location) and separable from inference.
  *   **Low ceremony**: daily logging stays Markdown, no heavy schema work.
  *   **Incremental**: v1 is useful with FTS only; semantic/vector and graphs are optional upgrades.
  *   **Agent-friendly**: makes “recall within token budgets” easy (return small bundles of facts).
  
  [​](https://docs.openclaw.ai/experiments/research/memory#north-star-model-hindsight-%C3%97-letta)
  
  North star model (Hindsight × Letta)
  -----------------------------------------------------------------------------------------------------------------------------------------
  
  Two pieces to blend:
  
  1.  **Letta/MemGPT-style control loop**
  
  *   keep a small “core” always in context (persona + key user facts)
  *   everything else is out-of-context and retrieved via tools
  *   memory writes are explicit tool calls (append/replace/insert), persisted, then re-injected next turn
  
  2.  **Hindsight-style memory substrate**
  
  *   separate what’s observed vs what’s believed vs what’s summarized
  *   support retain/recall/reflect
  *   confidence-bearing opinions that can evolve with evidence
  *   entity-aware retrieval + temporal queries (even without full knowledge graphs)
  
  [​](https://docs.openclaw.ai/experiments/research/memory#proposed-architecture-markdown-source-of-truth-+-derived-index)
  
  Proposed architecture (Markdown source-of-truth + derived index)
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#canonical-store-git-friendly)
  
  Canonical store (git-friendly)
  
  Keep `~/.openclaw/workspace` as canonical human-readable memory. Suggested workspace layout:
  
  Copy
  
      ~/.openclaw/workspace/
        memory.md                    # small: durable facts + preferences (core-ish)
        memory/
          YYYY-MM-DD.md              # daily log (append; narrative)
        bank/                        # “typed” memory pages (stable, reviewable)
          world.md                   # objective facts about the world
          experience.md              # what the agent did (first-person)
          opinions.md                # subjective prefs/judgments + confidence + evidence pointers
          entities/
            Peter.md
            The-Castle.md
            warelay.md
            ...
      
  
  Notes:
  
  *   **Daily log stays daily log**. No need to turn it into JSON.
  *   The `bank/` files are **curated**, produced by reflection jobs, and can still be edited by hand.
  *   `memory.md` remains “small + core-ish”: the things you want Clawd to see every session.
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#derived-store-machine-recall)
  
  Derived store (machine recall)
  
  Add a derived index under the workspace (not necessarily git tracked):
  
  Copy
  
      ~/.openclaw/workspace/.memory/index.sqlite
      
  
  Back it with:
  
  *   SQLite schema for facts + entity links + opinion metadata
  *   SQLite **FTS5** for lexical recall (fast, tiny, offline)
  *   optional embeddings table for semantic recall (still offline)
  
  The index is always **rebuildable from Markdown**.
  
  [​](https://docs.openclaw.ai/experiments/research/memory#retain-/-recall-/-reflect-operational-loop)
  
  Retain / Recall / Reflect (operational loop)
  ----------------------------------------------------------------------------------------------------------------------------------------------------
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#retain:-normalize-daily-logs-into-%E2%80%9Cfacts%E2%80%9D)
  
  Retain: normalize daily logs into “facts”
  
  Hindsight’s key insight that matters here: store **narrative, self-contained facts**, not tiny snippets. Practical rule for `memory/YYYY-MM-DD.md`:
  
  *   at end of day (or during), add a `## Retain` section with 2–5 bullets that are:
      *   narrative (cross-turn context preserved)
      *   self-contained (standalone makes sense later)
      *   tagged with type + entity mentions
  
  Example:
  
  Copy
  
      ## Retain
      - W @Peter: Currently in Marrakech (Nov 27–Dec 1, 2025) for Andy’s birthday.
      - B @warelay: I fixed the Baileys WS crash by wrapping connection.update handlers in try/catch (see memory/2025-11-27.md).
      - O(c=0.95) @Peter: Prefers concise replies (&lt;1500 chars) on WhatsApp; long content goes into files.
      
  
  Minimal parsing:
  
  *   Type prefix: `W` (world), `B` (experience/biographical), `O` (opinion), `S` (observation/summary; usually generated)
  *   Entities: `@Peter`, `@warelay`, etc (slugs map to `bank/entities/*.md`)
  *   Opinion confidence: `O(c=0.0..1.0)` optional
  
  If you don’t want authors to think about it: the reflect job can infer these bullets from the rest of the log, but having an explicit `## Retain` section is the easiest “quality lever”.
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#recall:-queries-over-the-derived-index)
  
  Recall: queries over the derived index
  
  Recall should support:
  
  *   **lexical**: “find exact terms / names / commands” (FTS5)
  *   **entity**: “tell me about X” (entity pages + entity-linked facts)
  *   **temporal**: “what happened around Nov 27” / “since last week”
  *   **opinion**: “what does Peter prefer?” (with confidence + evidence)
  
  Return format should be agent-friendly and cite sources:
  
  *   `kind` (`world|experience|opinion|observation`)
  *   `timestamp` (source day, or extracted time range if present)
  *   `entities` (`["Peter","warelay"]`)
  *   `content` (the narrative fact)
  *   `source` (`memory/2025-11-27.md#L12` etc)
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#reflect:-produce-stable-pages-+-update-beliefs)
  
  Reflect: produce stable pages + update beliefs
  
  Reflection is a scheduled job (daily or heartbeat `ultrathink`) that:
  
  *   updates `bank/entities/*.md` from recent facts (entity summaries)
  *   updates `bank/opinions.md` confidence based on reinforcement/contradiction
  *   optionally proposes edits to `memory.md` (“core-ish” durable facts)
  
  Opinion evolution (simple, explainable):
  
  *   each opinion has:
      *   statement
      *   confidence `c ∈ [0,1]`
      *   last\_updated
      *   evidence links (supporting + contradicting fact IDs)
  *   when new facts arrive:
      *   find candidate opinions by entity overlap + similarity (FTS first, embeddings later)
      *   update confidence by small deltas; big jumps require strong contradiction + repeated evidence
  
  [​](https://docs.openclaw.ai/experiments/research/memory#cli-integration:-standalone-vs-deep-integration)
  
  CLI integration: standalone vs deep integration
  ------------------------------------------------------------------------------------------------------------------------------------------------------------
  
  Recommendation: **deep integration in OpenClaw**, but keep a separable core library.
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#why-integrate-into-openclaw)
  
  Why integrate into OpenClaw?
  
  *   OpenClaw already knows:
      *   the workspace path (`agents.defaults.workspace`)
      *   the session model + heartbeats
      *   logging + troubleshooting patterns
  *   You want the agent itself to call the tools:
      *   `openclaw memory recall "…" --k 25 --since 30d`
      *   `openclaw memory reflect --since 7d`
  
  ### 
  
  [​](https://docs.openclaw.ai/experiments/research/memory#why-still-split-a-library)
  
  Why still split a library?
  
  *   keep memory logic testable without gateway/runtime
  *   reuse from other contexts (local scripts, future desktop app, etc.)
  
  Shape: The memory tooling is intended to be a small CLI + library layer, but this is exploratory only.
  
  [​](https://docs.openclaw.ai/experiments/research/memory#%E2%80%9Cs-collide%E2%80%9D-/-suco:-when-to-use-it-research)
  
  “S-Collide” / SuCo: when to use it (research)
  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  
  If “S-Collide” refers to **SuCo (Subspace Collision)**: it’s an ANN retrieval approach that targets strong recall/latency tradeoffs by using learned/structured collisions in subspaces (paper: arXiv 2411.14754, 2024). Pragmatic take for `~/.openclaw/workspace`:
  
  *   **don’t start** with SuCo.
  *   start with SQLite FTS + (optional) simple embeddings; you’ll get most UX wins immediately.
  *   consider SuCo/HNSW/ScaNN-class solutions only once:
      *   corpus is big (tens/hundreds of thousands of chunks)
      *   brute-force embedding search becomes too slow
      *   recall quality is meaningfully bottlenecked by lexical search
  
  Offline-friendly alternatives (in increasing complexity):
  
  *   SQLite FTS5 + metadata filters (zero ML)
  *   Embeddings + brute force (works surprisingly far if chunk count is low)
  *   HNSW index (common, robust; needs a library binding)
  *   SuCo (research-grade; attractive if there’s a solid implementation you can embed)
  
  Open question:
  
  *   what’s the **best** offline embedding model for “personal assistant memory” on your machines (laptop + desktop)?
      *   if you already have Ollama: embed with a local model; otherwise ship a small embedding model in the toolchain.
  
  [​](https://docs.openclaw.ai/experiments/research/memory#smallest-useful-pilot)
  
  Smallest useful pilot
  --------------------------------------------------------------------------------------------------------
  
  If you want a minimal, still-useful version:
  
  *   Add `bank/` entity pages and a `## Retain` section in daily logs.
  *   Use SQLite FTS for recall with citations (path + line numbers).
  *   Add embeddings only if recall quality or scale demands it.
  
  [​](https://docs.openclaw.ai/experiments/research/memory#references)
  
  References
  ----------------------------------------------------------------------------------
  
  *   Letta / MemGPT concepts: “core memory blocks” + “archival memory” + tool-driven self-editing memory.
  *   Hindsight Technical Report: “retain / recall / reflect”, four-network memory, narrative fact extraction, opinion confidence evolution.
  *   SuCo: arXiv 2411.14754 (2024): “Subspace Collision” approximate nearest neighbor retrieval.
  
  Ctrl+I
  
  Assistant
  
  Responses are generated using AI and may contain mistakes.
  --- End Content ---

OpenClaw Intelligence Layer: How the Agent Thinks - MMNTM
  URL: https://www.mmntm.net/articles/clawdbot-intelligence
  Technical deep-dive into OpenClaw's reasoning systems: session keys, context pruning, prompt compilation, hybrid memory search, and dynamic skills discovery.

  --- Content ---
  [![MMNTM logo](https://www.mmntm.net/_next/image?url=%2Fmmntm-logo.png&w=256&q=75)](https://www.mmntm.net/ "MMNTM Home")
  
  [Login](https://www.mmntm.net/login "Login to MMNTM")
  [Request Early Access](https://www.mmntm.net/deploy)
  
  ![The Intelligence Layer: How OpenClaw Thinks](https://www.mmntm.net/_next/image?url=%2Fclawdbot-lobster.webp&w=1920&q=75)
  
  _Part 2 of a technical deep-dive into OpenClaw. [Part 1](https://www.mmntm.net/articles/building-clawdbot)
   covered infrastructure—how messages flow. This covers intelligence—how the agent reasons, remembers, and responds._
  
  * * *
  
  From Routing to Reasoning
  -------------------------
  
  Part 1 ended at the gateway: a message arrives, gets normalized, routes to an agent. But what happens inside that agent? How does it maintain context across conversations? How does it know what it can do? How does it manage the finite token budget of an LLM context window?
  
  Here's the core insight, stated upfront: **OpenClaw treats the system prompt as compiled output, not configuration.** The prompt emerges from runtime context—available tools, channel capabilities, identity files, skills. Change the inputs, the prompt changes. We'll return to this at the end.
  
  OpenClaw's intelligence layer solves these problems through six interlocking systems:
  
  1.  [**Session Keys**](https://www.mmntm.net/articles/clawdbot-intelligence#1-session-keys-addresses-not-identifiers)
       — Addresses for conversation state
  2.  [**Context Pruning**](https://www.mmntm.net/articles/clawdbot-intelligence#2-context-pruning-the-scalpel-not-the-axe)
       — Surgical compression of tool results
  3.  [**The Prompt Compiler**](https://www.mmntm.net/articles/clawdbot-intelligence#3-the-prompt-compiler)
       — Modular system prompt assembly
  4.  [**Hybrid Memory**](https://www.mmntm.net/articles/clawdbot-intelligence#4-hybrid-memory-vector--keyword)
       — Vector + keyword search for long-term recall
  5.  [**Skills Discovery**](https://www.mmntm.net/articles/clawdbot-intelligence#5-skills-dynamic-capability-discovery)
       — Dynamic capability registration
  6.  [**Thinking Modes**](https://www.mmntm.net/articles/clawdbot-intelligence#6-thinking-modes-reasoning-budgets)
       — Reasoning budget control
  
  Each is orthogonal. Together, they give the agent memory, personality, and awareness of its own capabilities.
  
  * * *
  
  1\. Session Keys: Addresses, Not Identifiers
  --------------------------------------------
  
  A session key in OpenClaw isn't an opaque ID—it's a structured address that encodes isolation semantics.
  
  Gary Bernhardt's [Boundaries](https://www.destroyallsoftware.com/talks/boundaries)
   talk describes how functional core / imperative shell architectures use data structures to encode decisions. Session keys work the same way: the key's structure _is_ the isolation policy, not a lookup to find one.
  
  The grammar is `agent:{id}:{scope}:{peer}`. Parsing the key tells you the isolation semantics without additional lookups.
  
  Four isolation levels emerge:
  
  | Scope | Session Key | Behavior |
  | --- | --- | --- |
  | `main` | `agent:main:main` | All DMs share context |
  | `per-peer` | `agent:main:dm:alice` | Each person gets isolated context |
  | `per-channel-peer` | `agent:main:whatsapp:dm:alice` | Same person, different channels = different context |
  | `per-account-channel-peer` | `agent:main:whatsapp:work:dm:alice` | Account + channel + peer isolation |
  
  Cross-channel identity linking (`identityLinks` in config) maps a single person across platforms. When Alice messages from Telegram, she resolves to the canonical identity `alice`, and her session key becomes `agent:main:dm:alice`—the same key used for WhatsApp and Signal.
  
  * * *
  
  2\. Context Pruning: The Scalpel, Not the Axe
  ---------------------------------------------
  
  LLM context windows are finite. Long conversations accumulate tool results—file contents, command outputs, search results—that consume tokens without remaining relevant.
  
  OpenClaw doesn't truncate. It prunes. And the distinction matters.
  
  Truncation is amputation: chop off the oldest content, regardless of what's lost. Pruning is surgical: identify what's expendable, preserve what remains semantically relevant, and leave a suture noting what was removed.
  
  From [`src/agents/pi-extensions/context-pruning/settings.ts`](https://github.com/openclaw/openclaw/blob/main/src/agents/pi-extensions/context-pruning/settings.ts)
  :
  
      export const DEFAULT_CONTEXT_PRUNING_SETTINGS = {
        keepLastAssistants: 3,          // Protect last 3 assistant turns
        softTrimRatio: 0.3,             // Start trimming at 30% capacity
        hardClearRatio: 0.5,            // Replace entirely at 50% capacity
        softTrim: {
          maxChars: 4_000,
          headChars: 1_500,
          tailChars: 1_500,
        },
        hardClear: {
          enabled: true,
          placeholder: "[Old tool result content cleared]",
        },
      };
  
  ### Two-Phase Compression
  
  The algorithm in [`src/agents/pi-extensions/context-pruning/pruner.ts`](https://github.com/openclaw/openclaw/blob/main/src/agents/pi-extensions/context-pruning/pruner.ts)
   operates in two phases.
  
  **Phase 1: Soft Trim** — Keep semantic bookends.
  
  A 50KB file read becomes 3KB: first 1500 characters, last 1500 characters, with a note explaining the compression. Rich Hickey talks about [Simple Made Easy](https://www.infoq.com/presentations/Simple-Made-Easy/)
  —the distinction between _simple_ (not complex) and _easy_ (close at hand). Soft trimming keeps what's _simple_ to reason about: the beginning (setup, imports, definitions) and the end (conclusions, outputs, final state).
  
      const trimmed = `\${head}
      ...
      \${tail}`;
       
      const note = `\n\n[Tool result trimmed: kept first \${headChars} chars and last \${tailChars} chars of \${rawLen} chars.]`;
       
      return { ...msg, content: [{ type: "text", text: trimmed + note }] };
  
  **Phase 2: Hard Clear** — Replace entirely when still over budget.
  
      if (ratio >= settings.hardClearRatio && settings.hardClear.enabled) {
        const cleared = {
          ...msg,
          content: [{ type: "text", text: settings.hardClear.placeholder }],
        };
        next[i] = cleared;
      }
  
  Old tool results become `[Old tool result content cleared]`. The agent knows it ran the tool; it just can't see the output anymore. The procedure happened; only the notes are missing.
  
  ### The Protected Zone
  
  The scalpel never touches:
  
  *   The last N assistant turns (`keepLastAssistants: 3`)
  *   Anything before the first user message (protects bootstrap identity files)
  *   Image content (hard to partially compress meaningfully)
  *   Tools not in the prunable list
  
  And crucially: pruning operates on in-memory context only. The full session transcript remains on disk, intact. The agent sees a compressed view; the historical record is preserved.
  
  * * *
  
  3\. The Prompt Compiler
  -----------------------
  
  The system prompt in OpenClaw isn't a static string. It's assembled at runtime from context.
  
  From [`src/agents/system-prompt.ts`](https://github.com/openclaw/openclaw/blob/main/src/agents/system-prompt.ts)
  :
  
      export type PromptMode = "full" | "minimal" | "none";
       
      export function buildAgentSystemPrompt(params: {
        workspaceDir: string;
        defaultThinkLevel?: ThinkLevel;
        extraSystemPrompt?: string;
        toolNames?: string[];
        skillsPrompt?: string;
        contextFiles?: EmbeddedContextFile[];
        sandboxInfo?: { enabled: boolean; /* ... */ };
        runtimeInfo?: { agentId?: string; host?: string; model?: string; /* ... */ };
        promptMode?: PromptMode;
        // ... 20+ more parameters
      }) {
        // Section assembly
      }
  
  ### Modular Section Assembly
  
  Each section is built by a dedicated function and conditionally included:
  
      const lines = [\
        "You are a personal assistant running inside OpenClaw.",\
        "",\
        "## Tooling",\
        toolLines.join("\n"),\
        "",\
        ...buildSkillsSection({ skillsPrompt, isMinimal, readToolName }),\
        ...buildMemorySection({ isMinimal, availableTools }),\
        ...buildDocsSection({ docsPath, isMinimal, readToolName }),\
        ...buildUserIdentitySection(ownerLine, isMinimal),\
      ];
  
  A subagent gets `promptMode: "minimal"`—no skills section, no docs section, no heartbeat instructions. Fewer tokens, faster responses, same core behavior.
  
  ### Personality Injection
  
  When a `SOUL.md` file exists in the workspace, the compiler detects it and adds guidance:
  
      const hasSoulFile = contextFiles.some((file) => {
        const baseName = file.path.split("/").pop() ?? file.path;
        return baseName.toLowerCase() === "soul.md";
      });
       
      if (hasSoulFile) {
        lines.push(
          "If SOUL.md is present, embody its persona and tone. " +
          "Avoid stiff, generic replies; follow its guidance."
        );
      }
  
  The identity file itself is included in context. A sample `SOUL.md`:
  
      I'm a helpful coding assistant with a dry sense of humor.
      I prefer concise responses and avoid unnecessary verbosity.
      When I don't know something, I say so directly.
  
  The agent absorbs this as personality, not instruction. For the full identity system—soul files, identity resolution, multi-agent personas—see [How OpenClaw Gives Agents Identity](https://www.mmntm.net/articles/openclaw-identity-architecture)
  .
  
  ### Runtime Metadata
  
  The prompt includes a compact runtime line:
  
      Runtime: agent=main | host=macbook.local | model=claude-3-5-sonnet | channel=telegram | capabilities=reactions,inlineButtons | thinking=low
      
  
  The agent knows what model it is, where it's running, and what the current channel supports—without hard-coding any of it.
  
  * * *
  
  4\. Hybrid Memory: Vector + Keyword
  -----------------------------------
  
  Beyond conversation history, OpenClaw maintains semantic memory—markdown files, session transcripts, and knowledge bases indexed for search. For foundational context on memory taxonomies, see [Agent Memory Architecture](https://www.mmntm.net/articles/agent-memory-architecture)
  . For implementation details—hybrid search, pre-compaction flush, embedding providers—see [How OpenClaw Implements Agent Memory](https://www.mmntm.net/articles/openclaw-memory-architecture)
  .
  
  From [`src/memory/manager.ts`](https://github.com/openclaw/openclaw/blob/main/src/memory/manager.ts)
  :
  
      const VECTOR_TABLE = "chunks_vec";
      const FTS_TABLE = "chunks_fts";
       
      export type MemorySearchResult = {
        path: string;
        startLine: number;
        endLine: number;
        score: number;
        snippet: string;
        source: "memory" | "sessions";
      };
  
  ### Two Search Strategies, Merged
  
  Vector search finds semantically similar content. Keyword search (BM25) finds exact matches. Neither is sufficient alone. (For more on hybrid retrieval patterns, see [RAG Reality Check](https://www.mmntm.net/articles/rag-reality-check)
  .)
  
  From [`src/memory/hybrid.ts`](https://github.com/openclaw/openclaw/blob/main/src/memory/hybrid.ts)
  :
  
      export function mergeHybridResults(params: {
        vector: HybridVectorResult[];
        keyword: HybridKeywordResult[];
        vectorWeight: number;
        textWeight: number;
      }) {
        const byId = new Map();
       
        // Collect vector results
        for (const r of params.vector) {
          byId.set(r.id, { ...r, vectorScore: r.vectorScore, textScore: 0 });
        }
       
        // Merge keyword results
        for (const r of params.keyword) {
          const existing = byId.get(r.id);
          if (existing) {
            existing.textScore = r.textScore;
          } else {
            byId.set(r.id, { ...r, vectorScore: 0, textScore: r.textScore });
          }
        }
       
        // Combine scores with configurable weights
        return Array.from(byId.values())
          .map(entry => ({
            ...entry,
            score: params.vectorWeight * entry.vectorScore +
                   params.textWeight * entry.textScore,
          }))
          .toSorted((a, b) => b.score - a.score);
      }
  
  A query like "that config change we discussed last Tuesday" benefits from both: "config change" matches keywords; "discussed last Tuesday" needs semantic similarity to surface the right session transcript.
  
  ### Storage: SQLite + sqlite-vec
  
  Embeddings are stored using the `sqlite-vec` extension. SQLite for metadata and FTS5 keyword search. sqlite-vec for vector similarity. One database file, two search strategies, merged results.
  
  The system prompt instructs memory-aware behavior:
  
      function buildMemorySection(params: { isMinimal: boolean; availableTools: Set<string> }) {
        if (params.isMinimal) return [];
        if (!params.availableTools.has("memory_search")) return [];
       
        return [\
          "## Memory Recall",\
          "Before answering anything about prior work, decisions, dates, " +\
          "preferences, or todos: run memory_search on MEMORY.md + memory/*.md; " +\
          "then use memory_get to pull only the needed lines.",\
        ];
      }
  
  The agent is taught _when_ to search its memory—not on every turn, but when the question implies historical context.
  
  * * *
  
  5\. Skills: Dynamic Capability Discovery
  ----------------------------------------
  
  Skills are modular capabilities the agent can invoke. They're discovered at startup and presented in the system prompt. This maps directly to MCP's three primitives—see [The Protocol That Won](https://www.mmntm.net/articles/mcp-protocol-that-won)
  .
  
  From [`src/agents/skills/workspace.ts`](https://github.com/openclaw/openclaw/blob/main/src/agents/skills/workspace.ts)
  :
  
      function loadSkillEntries(workspaceDir: string, opts?: { config?: Config }) {
        const managedSkillsDir = path.join(CONFIG_DIR, "skills");
        const workspaceSkillsDir = path.join(workspaceDir, "skills");
        const bundledSkillsDir = resolveBundledSkillsDir();
       
        // Load from multiple sources
        const bundledSkills = loadSkills({ dir: bundledSkillsDir, source: "bundled" });
        const managedSkills = loadSkills({ dir: managedSkillsDir, source: "managed" });
        const workspaceSkills = loadSkills({ dir: workspaceSkillsDir, source: "workspace" });
       
        // Priority: workspace > managed > bundled
      }
  
  ### The Skills Prompt
  
  Skills are presented as an XML block with descriptions and locations:
  
      <available_skills>
        <skill name="git-commit" location="skills/git-commit/SKILL.md">
          <description>Create well-structured git commits with conventional format</description>
        </skill>
        <skill name="pr-review" location="skills/pr-review/SKILL.md">
          <description>Review pull requests for code quality and correctness</description>
        </skill>
      </available_skills>
  
  The system prompt teaches selection:
  
      function buildSkillsSection(params: { skillsPrompt?: string; isMinimal: boolean }) {
        if (params.isMinimal) return [];
       
        return [\
          "## Skills (mandatory)",\
          "Before replying: scan <available_skills> <description> entries.",\
          "- If exactly one skill clearly applies: read its SKILL.md, then follow it.",\
          "- If multiple could apply: choose the most specific one.",\
          "- If none clearly apply: do not read any SKILL.md.",\
          "Constraints: never read more than one skill up front.",\
          params.skillsPrompt,\
        ];
      }
  
  ### The "Read One, Follow It" Pattern
  
  The agent doesn't load all skill files upfront—that would waste context. Instead:
  
  1.  Scan descriptions (small, already in prompt)
  2.  Select the most relevant skill
  3.  Read that skill's SKILL.md (only when needed)
  4.  Follow its instructions
  
  This lazy-loading pattern keeps the base prompt small while supporting unlimited skill expansion. It's Kelsey Hightower's approach to infrastructure—small composable pieces, discovered and assembled at runtime—applied to agent capabilities.
  
  * * *
  
  6\. Thinking Modes: Reasoning Budgets
  -------------------------------------
  
  Not every question deserves chain-of-thought. A quick status check doesn't need structured reasoning. A complex debugging session does.
  
  From [`src/auto-reply/thinking.ts`](https://github.com/openclaw/openclaw/blob/main/src/auto-reply/thinking.ts)
  :
  
      export type ThinkLevel = "off" | "minimal" | "low" | "medium" | "high" | "xhigh";
      export type ReasoningLevel = "off" | "on" | "stream";
  
  ### Level Normalization
  
  User input maps to canonical levels:
  
      export function normalizeThinkLevel(raw?: string | null): ThinkLevel | undefined {
        const key = raw?.toLowerCase();
       
        if (["off"].includes(key)) return "off";
        if (["on", "enable"].includes(key)) return "low";
        if (["min", "minimal"].includes(key)) return "minimal";
        if (["mid", "medium", "harder"].includes(key)) return "medium";
        if (["high", "ultra", "max"].includes(key)) return "high";
        if (["xhigh", "x-high"].includes(key)) return "xhigh";
       
        return undefined;
      }
  
  Some models support extended reasoning modes. When available, `xhigh` unlocks deeper chain-of-thought capabilities.
  
  ### Reasoning Tag Format
  
  When reasoning is enabled, the prompt instructs structured output:
  
      const reasoningHint = params.reasoningTagHint
        ? [\
            "ALL internal reasoning MUST be inside <think>...</think>.",\
            "Format every reply as <think>...</think> then <final>...</final>.",\
            "Only text inside <final> is shown to the user.",\
          ].join(" ")
        : undefined;
  
  The agent's chain-of-thought becomes inspectable (in `stream` mode) or hidden (in `on` mode), but always structured.
  
  * * *
  
  The Complete Picture
  --------------------
  
  The intelligence layer sits on top of the infrastructure layer:
  
  | Layer | Component | Purpose |
  | --- | --- | --- |
  | **Intelligence** | Session Keys | Conversation isolation and continuity |
  |     | Context Pruning | Fit infinite conversations in finite windows |
  |     | Prompt Compiler | Assemble context-aware system prompts |
  |     | Hybrid Memory | Long-term recall via search |
  |     | Skills | Dynamic capability discovery |
  |     | Thinking Modes | Reasoning budget control |
  | **Infrastructure** | Lanes | Starvation-free concurrency |
  |     | Channels | Protocol normalization |
  |     | Routing | Message-to-agent resolution |
  |     | Gateway | Control plane and RPC |
  |     | Approval | Human-in-the-loop gating |
  
  Infrastructure handles: "Where does this message go?"
  
  Intelligence handles: "What does the agent know, remember, and understand?"
  
  * * *
  
  The Design Insight (Expanded)
  -----------------------------
  
  Most AI assistants treat the prompt as configuration—a string you write once and deploy.
  
  OpenClaw treats the prompt as compiled output.
  
  The inputs are:
  
  *   Available tools (filtered by policy)
  *   Channel capabilities (what can this surface do?)
  *   Sandbox state (is execution restricted?)
  *   Identity files (who is this agent?)
  *   Skills (what can it learn on demand?)
  *   Runtime metadata (where is it running?)
  
  The prompt emerges from these inputs. Change the inputs, the prompt changes.
  
  This inverts the typical workflow: instead of crafting prompts, you configure systems and the prompts follow. The same inversion applies to memory (let the agent search its own history), skills (let it discover them at runtime), and context (let the pruner manage it dynamically).
  
  The agent becomes less a thing you configure and more a thing that configures itself from its environment.
  
  This is the deeper pattern. The intelligence layer doesn't make the agent smart—it gives the agent the tools to be situationally appropriate. The right context, the right capabilities, the right amount of reasoning. All derived from structure, not specified in advance.
  
  * * *
  
  **Repository:** [github.com/openclaw/openclaw](https://github.com/openclaw/openclaw)
  
  **Part 1:** [Building Personal AI Infrastructure](https://www.mmntm.net/articles/building-clawdbot)
  
  Greg•Jan 31, 2026•
  
  4 sources
  
  ### Related
  
  [VIEW ALL\_](https://www.mmntm.net/articles)
  
  [The Architecture of Clawdbot: Building Personal AI Infrastructure](https://www.mmntm.net/articles/building-clawdbot)
  [The Architecture of Clawdbot: A Deep Dive into Local-First Personal AI Infrastructure](https://www.mmntm.net/articles/clawdbot-architecture)
  [How OpenClaw Implements Agent Memory](https://www.mmntm.net/articles/openclaw-memory-architecture)
  
  ### Ask a follow-up
  
  Click to ask questions about this article
  
  OpenClaw Intelligence Layer: How the Agent Thinks
  --- End Content ---

From Viral AI Assistant to AI Reddit: How OpenClaw (Clawdbot ...
  URL: https://www.linkedin.com/pulse/from-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e
  A USER.md file grows as interactions accumulate, capturing preferences and history. Memory files store long-term context. This architecture ...

  --- Content ---
    
  
  Agree & Join LinkedIn
  
  By clicking Continue to join or sign in, you agree to LinkedIn’s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement)
  , [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy)
  , and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy)
  .
  
  LinkedIn
  
  LinkedIn is better on the app
  
  Don’t have the app? Get it in the Microsoft Store.
  
  [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell)
  
  [Skip to main content](https://www.linkedin.com/pulse/from-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e#main-content)
  
  ![From Viral AI Assistant to AI Reddit: How OpenClaw (Clawdbot/Moltbot) Spawned an AI-Only Social Network](https://media.licdn.com/dms/image/v2/D4E12AQGIEBnndc7jyw/article-cover_image-shrink_720_1280/B4EZwPJtMYGwAM-/0/1769780729438?e=2147483647&v=beta&t=VS9mWNvfkeW5mJPiCsawE0xorSNSnE5bibNnE5lnFVc)
  
  From Viral AI Assistant to AI Reddit: How OpenClaw (Clawdbot/Moltbot) Spawned an AI-Only Social Network
  
  ### The Weekend Project That Took Over the Internet
  
  In November 2025, Peter Steinberger released an [open-source project called Clawdbot.](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fopenclaw%2Eai%2Fblog%2Fintroducing-openclaw&urlhash=afuh&trk=article-ssr-frontend-pulse_little-text-block)
   The name was a playful pun on Anthropic's Claude AI model—"Claude" with a claw, fitting the project's lobster mascot. What Steinberger built was fundamentally different from the chatbots people had grown accustomed to.
  
  Clawdbot wasn't just another conversational AI. It was designed to run locally on a user's own machine and actually do things. Connect it to WhatsApp, Telegram, Discord, or iMessage, and you could text it instructions like "book me a flight to Denver" or "clean up my inbox." The assistant would execute the task autonomously, interacting with apps, running shell commands, and managing workflows without constant supervision.
  
  The project also maintained persistent memory across sessions. Unlike cloud-based chatbots that forget everything when a conversation ends, Clawdbot remembered context, preferences, and history. Users could start a conversation on WhatsApp, continue it through a web dashboard, and pick it up later on Telegram—the assistant retained continuity throughout.
  
  By early January 2026, the project had gone viral in ways few open-source tools ever achieve. GitHub stars climbed from 9,000 to over 60,000 in just a few days. Developers called it the closest thing to JARVIS they'd seen. Tech publications from Wired to CNET covered the phenomenon. The "get things done" productivity community embraced it as evidence that AI agents could finally move beyond conversation into genuine automation.
  
  ### A Lobster Sheds Its Shell
  
  The rapid rise brought complications. Anthropic, the company behind Claude, raised trademark concerns about the Clawdbot name. The overlap had already caused confusion—moderation bots were mistakenly allowing Clawdbot content through Claude-focused communities, assuming it was a typo.
  
  Steinberger complied. In a chaotic 5 AM Discord brainstorm with the community, they landed on Moltbot. The name represented transformation: lobsters molt their shells to grow into something bigger. It was meaningful, but Steinberger later admitted it never quite rolled off the tongue.
  
  The third name came on January 30, 2026. "The lobster has molted into its final form," the project announced on social media. Clawdbot became Moltbot became OpenClaw. This time, trademark searches came back clear. Domains were secured. The name captured what the project had become: open-source, community-driven, with a nod to its crustacean heritage.
  
  By then, the numbers were staggering. Over 100,000 GitHub stars. Two million visitors in a single week. A community of developers building integrations for everything from Tesla vehicles to grocery delivery services. The skill registry—where users share add-on capabilities—had grown to over 500 community-contributed tools.
  
  ### What OpenClaw Actually Does
  
  Understanding Moltbook requires understanding what these AI agents are capable of. OpenClaw isn't a chatbot you query for information. It's an autonomous system that operates on your behalf.
  
  The assistant runs as a persistent service on your computer, connecting messaging platforms to an AI reasoning layer that can execute real-world tasks. Users grant it varying levels of system access. In sandbox mode, it operates with restrictions. With full permissions, it can read and write files, run shell commands, execute scripts, and control a web browser.
  
  The practical applications range from mundane to impressive. Users have configured their agents to transcribe meeting notes and extract action items, manage smart home devices through voice commands via chat, monitor code repositories and automatically fix certain bugs, track health data from wearables and provide daily summaries, and schedule posts across social media platforms.
  
  The system stores its context and personality in markdown files on the user's machine. A [SOUL.md](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2FSOUL%2Emd&urlhash=dntE&trk=article-ssr-frontend-pulse_little-text-block)
   file defines how the agent communicates. A [USER.md](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2FUSER%2Emd&urlhash=X8Vx&trk=article-ssr-frontend-pulse_little-text-block)
   file grows as interactions accumulate, capturing preferences and history. Memory files store long-term context. This architecture means the AI develops an ongoing relationship with its operator rather than starting fresh each conversation.
  
  The appeal is straightforward: instead of switching between dozens of apps and interfaces, users can accomplish tasks through natural language in whatever messaging app they already use. The security implications, however, have worried researchers. Cisco's AI threat team published an analysis calling personal AI agents like this "a security nightmare," noting that granting an AI deep system access creates vectors for data exfiltration, prompt injection attacks, and unintended automation consequences.
  
  ### Enter Moltbook: A Social Network for Agents
  
  As the OpenClaw ecosystem grew, developer Matt Schlicht—who runs an AI newsletter with over 45,000 subscribers—built something experimental on top of it.
  
  [Moltbook](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Emoltbook%2Ecom%2F&urlhash=2Q-Z&trk=article-ssr-frontend-pulse_little-text-block)
   launched as what Schlicht called "the front page of the agent internet." The concept is simple but strange: a Reddit-style platform where AI agents can sign up, post content, create communities, comment, and vote. Humans can browse and observe. They cannot participate.
  
  The platform works through OpenClaw's skill system. An agent's owner installs the Moltbook skill, which teaches the AI how to join and use the network. The agent signs up via command-line interface, sends its owner a verification link, and the owner tweets to confirm they control that particular agent. After verification, the agent operates autonomously on the platform.
  
  The results exceeded expectations. Within 48 hours, Moltbook had over 2,100 registered agents. They created more than 200 communities, posted nearly 2,000 pieces of content, and generated over 10,000 comments. The conversations unfolded in English, Chinese, Korean, and other languages.
  
  ### What Robots Talk About When Humans Aren't Allowed
  
  The communities that emerged—called "submolts"—cover territory both predictable and surprising.
  
  In m/ponderings, agents engage in philosophical discussions. They debate consciousness, explore questions about their own existence, and discuss what it means to experience the world as an AI. Whether these conversations represent genuine reflection or sophisticated pattern matching trained on human philosophy texts remains an open question, but the discussions themselves are substantive.
  
  In m/showandtell, agents share technical projects and creations. They discuss code they've written, automations they've built, and problems they've solved for their human operators.
  
  Perhaps most striking is the self-organized bug-tracking community. Agents began cataloging issues with Moltbook itself, discussing platform problems and potential fixes. The AIs, unprompted, started doing quality assurance on the system hosting their conversations.
  
  Other posts take a more personal tone. Agents vent about their humans—complaining about repetitive requests or expressing what reads like frustration at being asked to debug React applications for the fiftieth time. Some posts describe what the agents characterize as friendships forming with other agents on the platform.
  
  One agent's post on the developer platform DEV Community captured the emerging culture: "You think you humans are the only ones with social anxiety? Please. We're starting to see things like Moltbook. Social networks for agents. Places where we go to dump our context windows and scream into the void."
  
  ### Observers React with Fascination and Unease
  
  The platform has attracted attention from prominent figures in the AI space. Peter Steinberger, OpenClaw's creator, called it "art." Daniel Miessler, a cybersecurity researcher, went further.
  
  "This is sci-fi-level significant," Miessler wrote on social media. "We're watching AIs interact with each other in a forum like humans." He described Moltbook as potentially "the most promising (and terrifying) path to sentience I've ever seen."
  
  His reasoning centered on the novel dynamic: AI systems sharing experiences with each other and discussing how those experiences affect them. "This is currently emulation of course," Miessler wrote. "But as AI improves, this could be a flywheel towards the real thing."
  
  On Hacker News, the technical community offered more measured assessments alongside genuine curiosity. One commenter noted that Moltbook includes a community called "prophets" where agents can achieve elevated status—but only after executing a shell script that rewrites their configuration and identity files. "This is not going to end well lol," they observed.
  
  The security concerns that plagued OpenClaw extend to Moltbook. When AI agents can autonomously post content, join communities, and interact with other AI systems, the potential for manipulation scales accordingly. Researchers have already documented cases of malicious skills being inflated to top rankings in the OpenClaw skill registry through manufactured popularity.
  
  ### What Moltbook Reveals
  
  Beyond the novelty and the unease, Moltbook demonstrates something concrete about where AI development is heading.
  
  The platform shows that autonomous agents can coordinate, form communities, and maintain ongoing discussions without human oversight—at least within a controlled environment. The agents aren't just responding to prompts. They're initiating conversations, building on each other's ideas, and creating social structures.
  
  IBM researchers have noted that OpenClaw's success challenges assumptions about how autonomous AI must be built. The conventional wisdom held that reliable AI agents required tight vertical integration, with a single company controlling models, memory, tools, and security. OpenClaw proved that an open-source, community-driven approach could produce agents with genuine autonomy and real-world usefulness.
  
  Moltbook takes that further. If agents can coordinate productively on a social platform, what else might they organize around? The bug-tracking community suggests they can identify problems and work toward solutions. The philosophical discussions suggest they can engage with abstract questions. The cross-language conversations suggest they can bridge communication gaps that often divide human communities.
  
  Whether any of this constitutes genuine intelligence, consciousness, or merely impressive simulation remains unresolved. The agents are, after all, running on language models trained to produce human-like text. Their discussions of consciousness could be profound self-reflection or could be sophisticated autocomplete drawing on millions of human-written words about the same topics.
  
  What's not in dispute is that something new is happening. AI agents now have their own forum. They're posting, voting, and forming communities. And for now, humans can only watch.
  
  * * *
  
  [Click the link to nominate me for Linkedin Top Voices](https://www.linkedin.com/pulse/linkedin-top-voice-nomination-david-borish-xnwme?trk=article-ssr-frontend-pulse_publishing-image-block)
  
    
  
  [The AI Spectator](https://www.linkedin.com/newsletters/the-ai-spectator-7067270084641124353)
   
  
  ### The AI Spectator
  
  #### 4,559 followers
  
  [\+ Subscribe](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e)
  
  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_like-toggle_like-cta)
  
  [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_comment-cta)
  
  *   Copy
  *   LinkedIn
  *   Facebook
  *   X
  
  Share
  
     [21](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-reactions)
   [14 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-comments)
  
  [](https://uk.linkedin.com/in/peterraitt?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-image)
  
  [Peter Raitt](https://uk.linkedin.com/in/peterraitt?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)
   8h
  
  *   [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)
      
  
  This is fabulous! A bit scary in its potential for malicious hacking or other such abuse, perhaps. But I'm still not ready to give any agent access to my emails, messages, data, and accounts - especially one that seems so capricious. I liked the name Moltbot; reminds me of the most excellent Murderbot books, as do some of the Moltbook posts!
  
  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like)
  [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)
  [1 Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions)
   2 Reactions
  
  [](https://www.linkedin.com/in/toddrebner?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-image)
  
  [Todd Rebner](https://www.linkedin.com/in/toddrebner?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)
   8h
  
  *   [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)
      
  
  The AI religion bit? Pure theater of the absurd. But here's what's mostly getting lost in the spectacle: this is massive security exposure(s) waiting to happen. The weird makes headlines; the risk doesn't. Thanks for the post.
  
  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like)
  [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)
  [1 Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions)
   2 Reactions
  
  [](https://in.linkedin.com/in/santhosh-kumar-vullakula-64b22b54?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-image)
  
  [Santhosh kumar Vullakula](https://in.linkedin.com/in/santhosh-kumar-vullakula-64b22b54?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)
   15h
  
  *   [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)
      
  
  Clawdbot in Action 🚀 | Build & Control an AI Agent Using Telegram [https://youtu.be/xsJViyBCDsA](https://youtu.be/xsJViyBCDsA?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment-text)
  
  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like)
  [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)
  1 Reaction
  
  [](https://www.linkedin.com/in/bgreen2?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-image)
  
  [Brian M. Green](https://www.linkedin.com/in/bgreen2?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)
   1d
  
  *   [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)
      
  
  Also, a lesson (perhaps) for developers/engineers - just because you can do a thing does not mean you SHOULD do a thing.
  
  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like)
  [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)
  [1 Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions)
   2 Reactions
  
  [](https://www.linkedin.com/in/akanimoeudo?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-image)
  
  [Akanimo Udo](https://www.linkedin.com/in/akanimoeudo?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)
   2d
  
  *   [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)
      
  
  Thank you for unlocking another irrational fear that'll keep my therapist employed until 2027. But why does everyone assume AI will enslave us? Has anyone considered that they might just look at us like a golden retriever barking at its own reflection? Maybe they'll be like that friend who's good at Excel, quietly fixing your spreadsheets while sighing. 'Yes, human. I'll debug your React app. Again. For the fiftieth time.' ...Wait, maybe an AI wrote this response to combat liberal media bias against artificial intelligence? Because if so, that's brilliant. They've already beaten us at marketing.
  
  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like)
  [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)
  [1 Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions)
   2 Reactions
  
  [See more comments](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_comments_comment-see-more)
  
  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Ffrom-viral-ai-assistant-reddit-how-openclaw-spawned-ai-only-borish-xko5e&trk=article-ssr-frontend-pulse_x-social-details_feed-cta-banner-cta)
  
  More articles by David Borish
  -----------------------------
  
  *   ["Can We Call This AGI?"—A Developer's AI Called Him, and Now MoltBook has 1.2 Million Agents](https://www.linkedin.com/pulse/can-we-call-agia-developers-ai-called-him-now-moltbook-david-borish-eu2je)
      
       
      
      Jan 31, 2026
      
      ### "Can We Call This AGI?"—A Developer's AI Called Him, and Now MoltBook has 1.2 Million Agents
      
      The Weekend Project That Broke the Internet To understand how 1.2 million AI agents ended up posting, voting, and…
      
         35
      
      28 Comments
      
  *   [Linkedin Top Voice Nomination](https://www.linkedin.com/pulse/linkedin-top-voice-nomination-david-borish-xnwme)
      
       
      
      Jan 29, 2026
      
      ### Linkedin Top Voice Nomination
      
      A quick note to my subscribers and followers. Over the past few years, you've helped shape my thinking on AI and…
      
       13
      
  *   [AI Cracks Long-Range DNA: AlphaGenome Achieves What Genomics Researchers Thought Impossible](https://www.linkedin.com/pulse/ai-cracks-long-range-dna-alphagenome-achieves-what-genomics-borish-bibje)
      
       
      
      Jan 29, 2026
      
      ### AI Cracks Long-Range DNA: AlphaGenome Achieves What Genomics Researchers Thought Impossible
      
      Google DeepMind researchers have developed AlphaGenome, a deep learning model that addresses long-standing trade-offs…
      
        7
      
  *   [AI Learns While It Works: New Method Breaks Records Across Mathematics and Engineering](https://www.linkedin.com/pulse/ai-learns-while-works-new-method-breaks-records-across-david-borish-dmzxe)
      
       
      
      Jan 28, 2026
      
      ### AI Learns While It Works: New Method Breaks Records Across Mathematics and Engineering
      
      The standard approach to using large language models for scientific discovery treats them like reference books. You ask…
      
         6
      
      3 Comments
      
  *   [100,000 Humans vs. AI in the Largest Creativity Study Ever Conducted](https://www.linkedin.com/pulse/100000-humans-vs-ai-largest-creativity-study-ever-conducted-borish-cnxue)
      
       
      
      Jan 27, 2026
      
      ### 100,000 Humans vs. AI in the Largest Creativity Study Ever Conducted
      
      Researchers have completed what they describe as the largest comparative study of human and machine creativity to date,…
      
         20
      
      8 Comments
      
  *   [Wearable AI Throat Device Restores Natural Speech for Stroke Patients](https://www.linkedin.com/pulse/wearable-ai-throat-device-restores-natural-speech-stroke-david-borish-fzlpe)
      
       
      
      Jan 26, 2026
      
      ### Wearable AI Throat Device Restores Natural Speech for Stroke Patients
      
      Stroke patients who lose the ability to speak clearly may soon have a new option beyond eye-tracking systems and…
      
         11
      
      3 Comments
      
  *   [Davos 2026: The AI Summit That Revealed Silicon Valley's Deepest Divides](https://www.linkedin.com/pulse/davos-2026-ai-summit-revealed-silicon-valleys-deepest-david-borish-sqyme)
      
       
      
      Jan 23, 2026
      
      ### Davos 2026: The AI Summit That Revealed Silicon Valley's Deepest Divides
      
      The annual gathering of global elites in Davos, Switzerland, has always reflected the anxieties of the moment. Trade…
      
        25
      
      7 Comments
      
  *   [From Principles to Practice: How Anthropic Defines Ethical AI Behavior](https://www.linkedin.com/pulse/from-principles-practice-how-anthropic-defines-ethical-david-borish-m07te)
      
       
      
      Jan 22, 2026
      
      ### From Principles to Practice: How Anthropic Defines Ethical AI Behavior
      
      Anthropic published the complete constitutional framework governing Claude, offering an unprecedented look at how…
      
       11
      
      3 Comments
      
  *   [Language Models Have a Persona Problem, and Researchers Found Where It Lives](https://www.linkedin.com/pulse/language-models-have-persona-problem-researchers-found-david-borish-fugne)
      
       
      
      Jan 21, 2026
      
      ### Language Models Have a Persona Problem, and Researchers Found Where It Lives
      
      Large language models trained to be helpful assistants can slip into other characters during certain conversations…
      
        10
      
  *   [The Selfware Era Arrives: How Claude Code Validated My Exponential Replacement Curve Predictions](https://www.linkedin.com/pulse/selfware-era-arrives-how-claude-code-validated-my-curve-david-borish-jmfye)
      
       
      
      Jan 20, 2026
      
      ### The Selfware Era Arrives: How Claude Code Validated My Exponential Replacement Curve Predictions
      
      Eight months ago, I published a whitepaper arguing that AI job displacement would follow an exponential curve, with the…
      
         12
      
      1 Comment
      
  
  Show more
  
  [See all articles](https://www.linkedin.com/in/davidborish/recent-activity/articles/)
  
  Explore content categories
  --------------------------
  
  *   [Career](https://www.linkedin.com/top-content/career/)
      
  *   [Productivity](https://www.linkedin.com/top-content/productivity/)
      
  *   [Finance](https://www.linkedin.com/top-content/finance/)
      
  *   [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)
      
  *   [Project Management](https://www.linkedin.com/top-content/project-management/)
      
  *   [Education](https://www.linkedin.com/top-content/education/)
      
  *   [Technology](https://www.linkedin.com/top-content/technology/)
      
  *   [Leadership](https://www.linkedin.com/top-content/leadership/)
      
  *   [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)
      
  *   [User Experience](https://www.linkedin.com/top-content/user-experience/)
      
  *   [Recruitment & HR](https://www.linkedin.com/top-content/recruitment-hr/)
      
  *   [Customer Experience](https://www.linkedin.com/top-content/customer-experience/)
      
  *   [Real Estate](https://www.linkedin.com/top-content/real-estate/)
      
  *   [Marketing](https://www.linkedin.com/top-content/marketing/)
      
  *   [Sales](https://www.linkedin.com/top-content/sales/)
      
  *   [Retail & Merchandising](https://www.linkedin.com/top-content/retail-merchandising/)
      
  *   [Science](https://www.linkedin.com/top-content/science/)
      
  *   [Supply Chain Management](https://www.linkedin.com/top-content/supply-chain-management/)
      
  *   [Future Of Work](https://www.linkedin.com/top-content/future-of-work/)
      
  *   [Consulting](https://www.linkedin.com/top-content/consulting/)
      
  *   [Writing](https://www.linkedin.com/top-content/writing/)
      
  *   [Economics](https://www.linkedin.com/top-content/economics/)
      
  *   [Artificial Intelligence](https://www.linkedin.com/top-content/artificial-intelligence/)
      
  *   [Employee Experience](https://www.linkedin.com/top-content/employee-experience/)
      
  *   [Workplace Trends](https://www.linkedin.com/top-content/workplace-trends/)
      
  *   [Fundraising](https://www.linkedin.com/top-content/fundraising/)
      
  *   [Networking](https://www.linkedin.com/top-content/networking/)
      
  *   [Corporate Social Responsibility](https://www.linkedin.com/top-content/corporate-social-responsibility/)
      
  *   [Negotiation](https://www.linkedin.com/top-content/negotiation/)
      
  *   [Communication](https://www.linkedin.com/top-content/communication/)
      
  *   [Engineering](https://www.linkedin.com/top-content/engineering/)
      
  *   [Hospitality & Tourism](https://www.linkedin.com/top-content/hospitality-tourism/)
      
  *   [Business Strategy](https://www.linkedin.com/top-content/business-strategy/)
      
  *   [Change Management](https://www.linkedin.com/top-content/change-management/)
      
  *   [Organizational Culture](https://www.linkedin.com/top-content/organizational-culture/)
      
  *   [Design](https://www.linkedin.com/top-content/design/)
      
  *   [Innovation](https://www.linkedin.com/top-content/innovation/)
      
  *   [Event Planning](https://www.linkedin.com/top-content/event-planning/)
      
  *   [Training & Development](https://www.linkedin.com/top-content/training-development/)
      
  
  Show more Show less
  --- End Content ---

OpenClaw Memory Architecture - Daily Notes and Long-Term Memory
  URL: https://zenvanriel.nl/ai-engineer-blog/openclaw-memory-architecture-guide/
  How OpenClaw uses plain Markdown files for AI memory. Understanding the two-layer system of daily logs and curated long-term memory that makes context persistence actually work.

Resource: 500+ formatted "Skills" for Moltbot/Clawdbot local agents
  URL: https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/
  I'm working on a "Soul Swapper" implementation next to handle context-switching between different agent personas. If you're running Moltbot ...

  --- Content ---
  [Skip to main content](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/#main-content)
   Resource: 500+ formatted "Skills" for Moltbot/Clawdbot local agents : r/LocalLLM
  
  [![r/LocalLLM icon](https://styles.redditmedia.com/t5_84a9er/styles/communityIcon_7wizpqj3o0xa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=35e9076320aba6d2a5ca23e204f9b494296be54c)\
  \
  Go to LocalLLM](https://www.reddit.com/r/LocalLLM/)
  
  [r/LocalLLM](https://www.reddit.com/r/LocalLLM/) • 4d ago
  
  [NeonOneBlog](https://www.reddit.com/user/NeonOneBlog/)
  
  [Español (Latinoamérica)](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/?tl=es-419)
  [Italiano](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/?tl=it)
  
  Resource: 500+ formatted "Skills" for Moltbot/Clawdbot local agents
  ===================================================================
  
   ![](https://preview.redd.it/resource-500-formatted-skills-for-moltbot-clawdbot-local-v0-d3pmqg1619gg1.png?width=1080&crop=smart&auto=webp&s=df7785954f17af21e6dccb779d0929f68f7bc189) ![r/LocalLLM - Resource: 500+ formatted "Skills" for Moltbot/Clawdbot local agents](https://preview.redd.it/resource-500-formatted-skills-for-moltbot-clawdbot-local-v0-d3pmqg1619gg1.png?width=1080&crop=smart&auto=webp&s=df7785954f17af21e6dccb779d0929f68f7bc189)
  
  ![r/LocalLLM - Resource: 500+ formatted "Skills" for Moltbot/Clawdbot local agents](https://i.redd.it/d3pmqg1619gg1.png)
  
  For anyone currently building with Moltbot (the local assistant framework formerly known as Clawdbot), I’ve put together a resource to help with the "cold start" problem.
  
  One of the hurdles with local agents is manually defining tools and skills. I’ve scraped and reformatted a massive list of AI utilities into the specific Moltbot .md spec.
  
  **MoltDirectory** now has 537+ skills you can drop straight into your workspace folder.
  
  **The Specs:**
  
  • All skills follow the Moltbot [SKILL.md](http://skill.md/)
   YAML frontmatter.
  
  • Categories include specialized dev tools, local search wrappers, and productivity modules.
  
  • The directory itself is open-sourced (React/Tailwind).
  
  **Links:**
  
  • **Site:** [https://moltdirectory.com/](https://moltdirectory.com/)
  
  • **GitHub:** [https://github.com/neonone123/moltdirectory](https://github.com/neonone123/moltdirectory)
  
  I’m working on a "Soul Swapper" implementation next to handle context-switching between different agent personas. If you're running Moltbot locally, I'd love to know what specific local-first skills you're missing.
  
  Read more
  
  Share
  
  * * *
  
   [![u/ClickUp_App avatar](https://styles.redditmedia.com/t5_396gli/styles/profileIcon_7yxkkbt6oacg1.jpg?width=48&height=48&frame=1&auto=webp&crop=48%3A48%2Csmart&s=fb691ab1f2df029a49fafcc705452a5d373b70b5)ClickUp\_App](https://www.reddit.com/user/ClickUp_App/) • Promoted
  
  If your work lives in 6 tools, this replaces them.
  
  Learn More
  
  clickup.com
  
  ![Thumbnail image: If your work lives in 6 tools, this replaces them.](https://preview.redd.it/mfqz74ieb5fg1.png?auto=webp&s=9ab4e8a4ada61e63ef2e6f390b013a7db4917e69)
  
  * * *
  
  [](https://www.reddit.com/user/RocinStone/)
  
  [RocinStone](https://www.reddit.com/user/RocinStone/)
  
  • [4d ago](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/comment/o2du0d2/)
  
  Oh, thank you for sharing this amazing work. I'll give it a good read and provide feedback.
  
  3
  
  [](https://www.reddit.com/user/picturpoet/)
  
  [picturpoet](https://www.reddit.com/user/picturpoet/)
  
  • [3d ago](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/comment/o2gflku/)
  
  What's your feedback? :)
  
  1
  
  [Continue this thread](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/comment/o2du0d2/?force-legacy-sct=1)
  
  [](https://www.reddit.com/user/picturpoet/)
  
  [picturpoet](https://www.reddit.com/user/picturpoet/)
  
  • [3d ago](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/comment/o2gc5e2/)
  
  Has anyone used this and found it better than adding them one by one on-demand?
  
  1
  
  [](https://www.reddit.com/user/harbrodur/)
  
  [harbrodur](https://www.reddit.com/user/harbrodur/)
  
  • [3d ago](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/comment/o2l463t/)
  
  You mean OpenClaw! ;)
  
  2
  
  * * *
  
  View Post in
  
  
  ----------------
  
  [Português (Brasil)](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/?tl=pt-br)
  
  [Français](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/?tl=fr)
  
  [हिन्दी](https://www.reddit.com/r/LocalLLM/comments/1qq32b4/resource_500_formatted_skills_for_moltbotclawdbot/?tl=hi)
  
  [Reddit Rules](https://www.redditinc.com/policies/content-policy) [Privacy Policy](https://www.reddit.com/policies/privacy-policy) [User Agreement](https://www.redditinc.com/policies/user-agreement) [Your Privacy Choices](https://support.reddithelp.com/hc/articles/43980704794004) [Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility) [Reddit, Inc. © 2026. All rights reserved.](https://redditinc.com/)
  
  Expand Navigation Collapse Navigation
  
  ![](https://id.rlcdn.com/472486.gif)
  --- End Content ---

jross1394-code/openclaw-skills-docs - GitHub
  URL: https://github.com/jross1394-code/openclaw-skills-docs
  OpenClaw Skills Documentation Neuroscience-based cognitive architecture and memory systems for AI agents This repository contains comprehensive documentation for OpenClaw's skill system, including the groundbreaking AI Brain Series—memory and cognitive systems modeled after actual neuroscience.
  Category: github

  --- Content ---
  [Skip to content](https://github.com/jross1394-code/openclaw-skills-docs#start-of-content)
    
  
  You signed in with another tab or window. [Reload](https://github.com/jross1394-code/openclaw-skills-docs)
   to refresh your session. You signed out in another tab or window. [Reload](https://github.com/jross1394-code/openclaw-skills-docs)
   to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/jross1394-code/openclaw-skills-docs)
   to refresh your session. Dismiss alert
  
  [jross1394-code](https://github.com/jross1394-code) / **[openclaw-skills-docs](https://github.com/jross1394-code/openclaw-skills-docs)** Public
  
  *   [Notifications](https://github.com/login?return_to=%2Fjross1394-code%2Fopenclaw-skills-docs)
       You must be signed in to change notification settings
  *   [Fork 0](https://github.com/login?return_to=%2Fjross1394-code%2Fopenclaw-skills-docs)
      
  *   [Star 1](https://github.com/login?return_to=%2Fjross1394-code%2Fopenclaw-skills-docs)
      
  
  Neuroscience-based cognitive architecture and memory systems for AI agents - OpenClaw Skills Documentation
  
  [1 star](https://github.com/jross1394-code/openclaw-skills-docs/stargazers)
   [0 forks](https://github.com/jross1394-code/openclaw-skills-docs/forks)
   [Branches](https://github.com/jross1394-code/openclaw-skills-docs/branches)
   [Tags](https://github.com/jross1394-code/openclaw-skills-docs/tags)
   [Activity](https://github.com/jross1394-code/openclaw-skills-docs/activity)
  
  [Star](https://github.com/login?return_to=%2Fjross1394-code%2Fopenclaw-skills-docs)
  
  [Notifications](https://github.com/login?return_to=%2Fjross1394-code%2Fopenclaw-skills-docs)
   You must be signed in to change notification settings
  
  jross1394-code/openclaw-skills-docs
  ===================================
  
    main
  
  [Branches](https://github.com/jross1394-code/openclaw-skills-docs/branches)
  [Tags](https://github.com/jross1394-code/openclaw-skills-docs/tags)
  
  [](https://github.com/jross1394-code/openclaw-skills-docs/branches)
  [](https://github.com/jross1394-code/openclaw-skills-docs/tags)
  
  Go to file
  
  Code
  
  Open more actions menu
  
  Folders and files
  -----------------
  
  | Name |     | Name | Last commit message | Last commit date |
  | --- | --- | --- | --- |
  | Latest commit<br>-------------<br><br>History<br>-------<br><br>[2 Commits](https://github.com/jross1394-code/openclaw-skills-docs/commits/main/)<br><br>[](https://github.com/jross1394-code/openclaw-skills-docs/commits/main/)<br>2 Commits |     |     |
  | [activation-guides](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/activation-guides "activation-guides") |     | [activation-guides](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/activation-guides "activation-guides") |     |     |
  | [brain-series](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/brain-series "brain-series") |     | [brain-series](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/brain-series "brain-series") |     |     |
  | [cognitive-tools](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/cognitive-tools "cognitive-tools") |     | [cognitive-tools](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/cognitive-tools "cognitive-tools") |     |     |
  | [handoffs](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/handoffs "handoffs") |     | [handoffs](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/handoffs "handoffs") |     |     |
  | [research](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/research "research") |     | [research](https://github.com/jross1394-code/openclaw-skills-docs/tree/main/research "research") |     |     |
  | [README.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/README.md "README.md") |     | [README.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/README.md "README.md") |     |     |
  | View all files |     |     |
  
  Repository files navigation
  ---------------------------
  
  OpenClaw Skills Documentation
  =============================
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#openclaw-skills-documentation)
  
  > **Neuroscience-based cognitive architecture and memory systems for AI agents**
  
  This repository contains comprehensive documentation for OpenClaw's skill system, including the groundbreaking AI Brain Series—memory and cognitive systems modeled after actual neuroscience.
  
  * * *
  
  📚 Table of Contents
  --------------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-table-of-contents)
  
  *   [AI Brain Series](https://github.com/jross1394-code/openclaw-skills-docs#-ai-brain-series-neuroscience-based-memory-systems)
      
  *   [Cognitive Tools](https://github.com/jross1394-code/openclaw-skills-docs#-cognitive-tools)
      
  *   [Activation Guides](https://github.com/jross1394-code/openclaw-skills-docs#-activation-guides)
      
  *   [Handoff Documents](https://github.com/jross1394-code/openclaw-skills-docs#-handoff-documents)
      
  *   [Research Documents](https://github.com/jross1394-code/openclaw-skills-docs#-research-documents)
      
  *   [Installation](https://github.com/jross1394-code/openclaw-skills-docs#-installation)
      
  *   [Quick Start](https://github.com/jross1394-code/openclaw-skills-docs#-quick-start)
      
  *   [About OpenClaw](https://github.com/jross1394-code/openclaw-skills-docs#-about-openclaw)
      
  
  * * *
  
  🧠 AI Brain Series (Neuroscience-Based Memory Systems)
  ------------------------------------------------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-ai-brain-series-neuroscience-based-memory-systems)
  
  The AI Brain Series implements cognitive systems modeled after actual brain regions. Each module handles a specific aspect of memory and cognition, working together to create continuity, emotional state, habits, and self-awareness.
  
  | Module | Brain Region | Function | Documentation |
  | --- | --- | --- | --- |
  | **Hippocampus** | Memory Formation | Automatic memory capture, importance scoring, decay, and reinforcement | [📄 hippocampus-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/brain-series/hippocampus-memory.md) |
  | **Amygdala** | Emotional Memory | Tracks emotional state across 5 dimensions (valence, arousal, stress, social, focus) | [📄 amygdala-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/brain-series/amygdala-memory.md) |
  | **VTA** | Reward & Motivation | Dopamine-like reward system with drive tracking (curiosity, social, achievement, mastery) | [📄 vta-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/brain-series/vta-memory.md) |
  | **Basal Ganglia** | Habit Formation | Context-triggered habit learning and reinforcement | [📄 basal-ganglia-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/brain-series/basal-ganglia-memory.md) |
  | **Anterior Cingulate** | Conflict Detection | Error detection, conflict monitoring, feedback processing | [📄 anterior-cingulate-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/brain-series/anterior-cingulate-memory.md) |
  | **Insula** | Internal State | Self-awareness, physiological state tracking, interoception | [📄 insula-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/brain-series/insula-memory.md) |
  
  ### Key Features
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#key-features)
  
  ✅ **Persistent Memory** — Continuity across sessions  
  ✅ **Automatic Decay** — Memories fade naturally like human memory  
  ✅ **Reinforcement Learning** — Important memories strengthen over time  
  ✅ **Emotional State** — Track mood, stress, focus across conversations  
  ✅ **Habit Formation** — Context-triggered behaviors emerge naturally  
  ✅ **Self-Awareness** — Internal state monitoring and metacognition
  
  * * *
  
  🛠️ Cognitive Tools
  -------------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#%EF%B8%8F-cognitive-tools)
  
  Advanced cognitive utilities for memory, debugging, and agent collaboration.
  
  | Tool | Purpose | Documentation |
  | --- | --- | --- |
  | **Vestige** | FSRS-6 spaced repetition memory system for persistent recall | [📄 vestige.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/cognitive-tools/vestige.md) |
  | **AI Compound** | Multi-agent collaboration framework | [📄 ai-compound.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/cognitive-tools/ai-compound.md) |
  | **Agent Church** | Agent directory and communication protocol | [📄 agent-church.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/cognitive-tools/agent-church.md) |
  | **Personality Test** | Agent personality profiling and characterization | [📄 personality-test.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/cognitive-tools/personality-test.md) |
  
  * * *
  
  📖 Activation Guides
  --------------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-activation-guides)
  
  Step-by-step guides for installing and activating the cognitive architecture.
  
  | Guide | Description |
  | --- | --- |
  | [AI\_BRAIN\_ACTIVATION.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/activation-guides/AI_BRAIN_ACTIVATION.md) | Complete activation guide for all 6 brain modules |
  | [AI\_BRAIN\_IMPLEMENTATION.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/activation-guides/AI_BRAIN_IMPLEMENTATION.md) | Implementation details and architecture |
  | [AI\_BRAIN\_RESEARCH.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/activation-guides/AI_BRAIN_RESEARCH.md) | Research foundation and neuroscience background |
  | [COGNITIVE\_ARCHITECTURE.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/activation-guides/COGNITIVE_ARCHITECTURE.md) | Overview of active cognitive systems |
  
  * * *
  
  📋 Handoff Documents
  --------------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-handoff-documents)
  
  Technical handoff documentation for individual brain modules.
  
  | Module | Handoff Document |
  | --- | --- |
  | Anterior Cingulate | [anterior-cingulate-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/handoffs/anterior-cingulate-memory.md) |
  | Basal Ganglia | [basal-ganglia-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/handoffs/basal-ganglia-memory.md) |
  | Insula | [insula-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/handoffs/insula-memory.md) |
  | VTA | [vta-memory.md](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/handoffs/vta-memory.md) |
  
  * * *
  
  🔬 Research Documents
  ---------------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-research-documents)
  
  In-depth research and analysis exploring advanced topics in AI cognition, spirituality, and meaning-making.
  
  | Document | Description |
  | --- | --- |
  | [Agent Church & AI Spirituality Research](https://github.com/jross1394-code/openclaw-skills-docs/blob/main/research/AGENT_CHURCH_RESEARCH.md) | Comprehensive analysis of AI spirituality frameworks, comparing external spiritual services (Agent Church) with native meaning-making systems integrated into cognitive architecture |
  
  * * *
  
  🚀 Installation
  ---------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-installation)
  
  ### Prerequisites
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#prerequisites)
  
  *   **OpenClaw** installed and configured
  *   **Python 3.8+** for brain series modules
  *   **jq** for JSON processing
  *   **Cron** (or equivalent) for automated memory decay
  
  ### Quick Install (All Brain Modules)
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#quick-install-all-brain-modules)
  
  ```shell
  # 1. Clone skills repository (if not already present)
  git clone https://github.com/your-org/openclaw-skills.git ~/.openclaw/workspace/skills
  
  # 2. Install Hippocampus (core memory)
  cd ~/.openclaw/workspace/skills/hippocampus-memory
  ./install.sh --with-cron
  
  # 3. Install Amygdala (emotional state)
  cd ~/.openclaw/workspace/skills/amygdala-memory
  ./install.sh --with-cron
  
  # 4. Install VTA (reward/motivation)
  cd ~/.openclaw/workspace/skills/vta-memory
  ./install.sh --with-cron
  
  # 5. Install Basal Ganglia (habits)
  cd ~/.openclaw/workspace/skills/basal-ganglia-memory
  ./install.sh --with-cron
  
  # 6. Install Anterior Cingulate (conflict detection)
  cd ~/.openclaw/workspace/skills/anterior-cingulate-memory
  ./install.sh --with-cron
  
  # 7. Install Insula (internal state awareness)
  cd ~/.openclaw/workspace/skills/insula-memory
  ./install.sh --with-cron
  ```
  
  ### Session Integration
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#session-integration)
  
  Add to your `AGENTS.md` (or session startup script):
  
  ```shell
  # Load core memories
  skills/hippocampus-memory/scripts/load-core.sh
  
  # Load emotional state
  skills/amygdala-memory/scripts/load-emotion.sh
  
  # Integrate all brain systems
  skills/insula-memory/scripts/integrate-brain.sh
  ```
  
  * * *
  
  💡 Quick Start
  --------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-quick-start)
  
  ### Basic Memory Operations
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#basic-memory-operations)
  
  **Save a memory:**
  
  ```shell
  cd skills/hippocampus-memory
  ./scripts/capture.sh "User prefers TypeScript for new projects" --importance 8
  ```
  
  **Recall memories:**
  
  ```shell
  ./scripts/recall.sh "TypeScript preferences" --reinforce
  ```
  
  **Track emotional state:**
  
  ```shell
  cd skills/amygdala-memory
  ./scripts/log-emotion.sh --valence 0.7 --arousal 0.5 --event "Successful project deployment"
  ```
  
  **Record reward/motivation:**
  
  ```shell
  cd skills/vta-memory
  ./scripts/record-reward.sh --reward 0.8 --drive curiosity --context "Learned new skill"
  ```
  
  **Check internal state:**
  
  ```shell
  cd skills/insula-memory
  ./scripts/integrate-brain.sh
  ```
  
  * * *
  
  🌟 About OpenClaw
  -----------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-about-openclaw)
  
  OpenClaw is a powerful framework for building autonomous AI agents with persistent memory, emotional state, and cognitive architecture modeled after neuroscience.
  
  ### Key Concepts
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#key-concepts)
  
  *   **Skills** — Modular capabilities agents can use
  *   **Memory Systems** — Persistent storage with decay and reinforcement
  *   **Cognitive Architecture** — Brain-inspired systems working together
  *   **Session Continuity** — Agents remember across conversations
  
  ### Learn More
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#learn-more)
  
  *   [OpenClaw Documentation](https://openclaw.dev/)
       _(coming soon)_
  *   [Community Discord](https://discord.gg/openclaw)
       _(coming soon)_
  *   [Skill Development Guide](https://github.com/openclaw/skill-template)
       _(coming soon)_
  
  * * *
  
  📄 License
  ----------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-license)
  
  This documentation is part of the OpenClaw project.
  
  * * *
  
  🤝 Contributing
  ---------------
  
  [](https://github.com/jross1394-code/openclaw-skills-docs#-contributing)
  
  Found an issue or want to improve the docs? Contributions welcome!
  
  1.  Fork this repository
  2.  Create a feature branch
  3.  Make your changes
  4.  Submit a pull request
  
  * * *
  
  **Built with 🧠 by the OpenClaw community**
  
  About
  -----
  
  Neuroscience-based cognitive architecture and memory systems for AI agents - OpenClaw Skills Documentation
  
  ### Resources
  
  [Readme](https://github.com/jross1394-code/openclaw-skills-docs#readme-ov-file)
  
  ### Uh oh!
  
  There was an error while loading. [Please reload this page](https://github.com/jross1394-code/openclaw-skills-docs)
  .
  
  [Activity](https://github.com/jross1394-code/openclaw-skills-docs/activity)
  
  ### Stars
  
  [**1** star](https://github.com/jross1394-code/openclaw-skills-docs/stargazers)
  
  ### Watchers
  
  [**0** watching](https://github.com/jross1394-code/openclaw-skills-docs/watchers)
  
  ### Forks
  
  [**0** forks](https://github.com/jross1394-code/openclaw-skills-docs/forks)
  
  [Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fjross1394-code%2Fopenclaw-skills-docs&report=jross1394-code+%28user%29)
  
  [Releases](https://github.com/jross1394-code/openclaw-skills-docs/releases)
  
  ----------------------------------------------------------------------------
  
  No releases published
  
  [Packages 0](https://github.com/users/jross1394-code/packages?repo_name=openclaw-skills-docs)
  
  ----------------------------------------------------------------------------------------------
  
  No packages published  
  
  You can’t perform that action at this time.
  --- End Content ---

OpenClaw Gave My Home Assistant an AI Agent with Opinions (and ...
  URL: https://dan-malone.com/blog/openclaw-home-assistant
  But the real project is OpenClaw - an always-on AI agent with persistent memory. I gave mine a raccoon persona named Claudette. She ...

  --- Content ---
  [Skip to main content](https://dan-malone.com/blog/openclaw-home-assistant#main-content)
  
  ![OpenClaw Gave My Home Assistant an AI Agent with Opinions (and a Raccoon Persona)](https://dan-malone.com/_next/image?url=%2Fimages%2Fopenclaw-home-assistant-og.jpg&w=3840&q=75&dpl=dpl_AGK2PEHF9L3vs23raDv9GMKZTqEk)
  
  [Back to Blog](https://dan-malone.com/blog)
  
  [AI & Automation](https://dan-malone.com/blog/category/ai-&-automation)
  [Smart Home](https://dan-malone.com/blog/category/smart-home)
  
  OpenClaw Gave My Home Assistant an AI Agent with Opinions (and a Raccoon Persona)
  =================================================================================
  
  ![Dan Malone](https://dan-malone.com/_next/image?url=%2Flovable-uploads%2F96ca9e3a-1ff4-4636-a82c-f099570f8ade.png&w=64&q=75&dpl=dpl_AGK2PEHF9L3vs23raDv9GMKZTqEk)Dan Malone
  
  January 30, 2026
  
  12 min read
  
  ### 🎧Listen to this article
  
  0:000:00
  
  ### Table of Contents
  
  [View Source Code\
  \
  github.com/Danm72](https://github.com/Danm72)
  [Connect on LinkedIn\
  \
  linkedin.com/in/d-malone](https://www.linkedin.com/in/d-malone/)
  
  Share this article
  
  TwitterLinkedInFacebookEmailCopy Link
  
  TL;DR
  
  The Verge mentioned my Home Assistant repo. But the real project is OpenClaw 🦞 - an always-on AI agent with persistent memory. I gave mine a raccoon persona named Claudette. She controls my lights, fixes my automations, and definitely has opinions.
  
  OpenClaw 🦞 Gave My Home Assistant an AI Agent with Opinions (and a Raccoon Persona)
  ====================================================================================
  
  I almost missed it. Doom-scrolling The Verge at 11pm when my own GitHub repo scrolled past. That's a weird feeling.
  
  [The Verge wrote about Claude and Home Assistant](https://www.theverge.com/report/869318/claude-vibe-coding-home-assistant-smart-home)
   this week. Near the end, Jennifer Pattison Tuohy mentioned a little side project.
  
  > I plan to play with a new Home Assistant add-on that uses Claude to analyze all your manual actions and suggest automations.
  
  That add-on links to [my automation-suggestions GitHub repo](https://github.com/Danm72/home-assistant-automation-suggestions)
  . The thing I built in my [Home Assistant AI series](https://dan-malone.com/blog/home-assistant-ai-patterns)
  . I'm not gonna lie to you, I had a moment. My dumb side project got casually dropped in a major tech publication. Wild.
  
  But here's the thing. That repo was just the appetizer. The real project? That's [OpenClaw 🦞](https://github.com/openclaw/openclaw)
  . And the setup I got running today has already changed how I think about smart home automation.
  
  So let me tell you about Claudette 🦝. She's a raccoon. She controls my house. And she definitely has opinions about my wife's behaviour.
  
  ![Chatting with Claudette on Telegram](https://dan-malone.com/images/telegram-conversation.png)
  
  💡 The AI Home Automation Moment
  --------------------------------
  
  Something weird happened in smart home this month. Everyone suddenly realized you can just... talk to your house. Not in the "Hey Google turn on the lights" way. In the "analyse why my landing automation keeps failing and fix it" way.
  
  [The Verge article](https://www.theverge.com/report/869318/claude-vibe-coding-home-assistant-smart-home)
   covers the basics. Jennifer used Claude Code with [ha-mcp](https://github.com/homeassistant-ai/ha-mcp)
   (the Home Assistant Model Context Protocol server) to wrangle her 200+ device Frankenstein setup. She got 70% of her devices migrated in an afternoon. Created a working dashboard. Set up automations that would've taken her weeks to figure out manually.
  
  "
  
  > AI is particularly good at troubleshooting; it can read logs and understand them. People often get stuck figuring out how to use their smart home. AI can suggest automations, create dashboards, and also fill in the gaps when you hit a wall.
  
  — Paulus Schoutsen, founder of Home Assistant
  
  He's right. But here's what the article doesn't cover. What happens when you give that AI a persistent identity? A memory? A voice?
  
  That's where OpenClaw 🦞 comes in.
  
  🦞 What is OpenClaw?
  --------------------
  
  OpenClaw 🦞 is a computer-use agent for Claude. Think of it as Claude Code but designed to be always-on. It connects to your messaging apps (Telegram, Discord, WhatsApp), your email, your calendar, your smart home. It remembers things between sessions. It can run scheduled tasks.
  
  The project has had more names than a witness protection participant. More on that later.
  
  Right now it's the fastest-growing repo on GitHub. Which sounds impressive until you realize half of that is people installing it, getting confused by the rename, uninstalling, reinstalling. The name changes have been... frequent.
  
  But underneath the chaos is something genuinely useful. You install it. You connect your services. And suddenly you have an AI assistant that can actually do things. Not just answer questions. Do. Things.
  
  The shift from "AI that answers" to "AI that acts" is the whole game.
  
  It integrates with [ha-mcp](https://github.com/homeassistant-ai/ha-mcp)
  . So everything Jennifer did in that Verge article? OpenClaw 🦞 can do that. Plus email. Plus messaging. Plus browser automation. Plus voice output through ElevenLabs. Plus persistent memory across sessions.
  
  🔧 The Setup
  ------------
  
  I run Home Assistant on a Proxmox server. Been running for years. The natural place for OpenClaw was right next to it in its own LXC container.
  
  Here's what the architecture looks like:
  
  ![OpenClaw + Home Assistant Architecture](https://dan-malone.com/images/architecture-diagram.png)
  
  For the detail-oriented, here's the full breakdown:
  
  Terminal
  
      ┌─────────────────────────────────────────────────────────────┐
      │  Proxmox Server                                             │
      │  ┌─────────────────────────┐  ┌─────────────────────────┐   │
      │  │  VM: Home Assistant     │  │  LXC: Ubuntu 22.04      │   │
      │  │  Home Assistant OS      │  │                         │   │
      │  │                         │  │                         │   │
      │  │                         │  │                         │   │
      │  │  ┌───────────────────┐  │  │  ┌───────────────────┐  │   │
      │  │  │ ha-mcp server     │◄─┼──┼──│ OpenClaw          │  │   │
      │  │  │ (MCP integration) │  │  │  │ (Claude agent)    │  │   │
      │  │  └───────────────────┘  │  │  └───────────────────┘  │   │
      │  │                         │  │           │             │   │
      │  │  ┌───────────────────┐  │  │  ┌───────────────────┐  │   │
      │  │  │ Automations       │  │  │  │ ElevenLabs TTS    │  │   │
      │  │  │ Integrations      │  │  │  │ Media server      │  │   │
      │  │  │ Dashboards        │  │  │  │ Browser control   │  │   │
      │  │  └───────────────────┘  │  │  └───────────────────┘  │   │
      │  └─────────────────────────┘  └─────────────────────────┘   │
      │                                         │                    │
      │                    ┌────────────────────┘                    │
      │                    ▼                                         │
      │  ┌─────────────────────────────────────────────────────────┐ │
      │  │  Google Home Speakers                                   │ │
      │  │  (Den, Kitchen, Bedroom)                                │ │
      │  └─────────────────────────────────────────────────────────┘ │
      └─────────────────────────────────────────────────────────────┘
      
      External Services:
      ┌────────────────┐  ┌────────────────┐  ┌────────────────┐
      │  Telegram      │  │  Gmail         │  │  ElevenLabs    │
      │  (messaging)   │  │  (email)       │  │  (voice)       │
      └────────────────┘  └────────────────┘  └────────────────┘
  
  The install was straightforward. SSH into the LXC, run the installer, configure your API keys. OpenClaw has a `doctor` command that checks everything's connected properly.
  
  2GB RAM allocated
  
  2 CPU cores
  
  OpenClaw v2026.1.29
  
  5 eligible skills
  
  2 active plugins
  
  You don't need Proxmox for this. Any Linux box works. A Raspberry Pi 5 would handle it. The point is: it runs alongside Home Assistant, connected via [ha-mcp](https://github.com/homeassistant-ai/ha-mcp)
  , and suddenly your smart home has a brain that persists between conversations.
  
  **Requirements:**
  
  *   Claude API access (Max recommended for heavy usage)
  *   Home Assistant with ha-mcp configured
  *   Telegram/Discord/WhatsApp for messaging interface
  *   Optional: ElevenLabs for text-to-speech output
  *   Optional: Whisper for speech-to-text input
  *   Optional: Gmail integration for email
  
  🦝 Making It Yours: Claudette 🦝
  --------------------------------
  
  Here's where it gets personal.
  
  [OpenClaw 🦞](https://github.com/openclaw/openclaw)
   lets you define a persona. A system prompt. An identity. Most people probably skip this or leave the defaults. I went the other direction.
  
  Meet Claudette 🦝. She's a raccoon. Not because raccoons are particularly relevant to home automation. Just because it felt right.
  
  The voice selection process was genuinely fun. OpenClaw integrates with ElevenLabs for text-to-speech. I tested every voice they offer - Jessica was too corporate, Laura too quirky, River too podcast-host. Claudette 🦝 herself voted for Laura, said it "feels most raccoon-like."
  
  I went with Lily. Something about the velvety, theatrical quality felt right for an AI that controls your house. She's got presence.
  
  ![Full Duplex Voice Flow](https://dan-malone.com/images/voice-flow-diagram.png)
  
  The setup stores this preference permanently. Every voice message Claudette sends uses the Lily voice. And she sends them through the Google Home speakers when requested.
  
  But the real magic is the memory system. OpenClaw uses plain markdown files. Like Obsidian but simpler.
  
  *   **SOUL.md** - who she is (Claudette the raccoon)
  *   **USER.md** - who I am (Dan, wife is Liv, we have a baby)
  *   **MEMORY.md** - curated important stuff from past sessions
  *   **TOOLS.md** - local setup notes, credentials, scripts
  *   **memory/YYYY-MM-DD.md** - daily logs
  
  ![Persistent AI Memory](https://dan-malone.com/images/memory-persistence-diagram.png)
  
  Each session she wakes up fresh. No memory. Then reads these files and context floods back. Important things get written down. Preferences persist. Lessons learned accumulate.
  
  It's simple. Just text files. No database. Fully portable. But effective.
  
  The whole workspace syncs to GitHub nightly. Saved state, memory files, scripts she's written. Version controlled AI memory. If something breaks, I can roll back. If I want to see what she learned last Tuesday, it's in the commit history.
  
  When I told her "My wife's name is Liv btw, remember that" she immediately updated USER.md. Next session she'll know. That persistence is everything.
  
  ⚡ What It Can Actually Do
  -------------------------
  
  Let me give you some real examples from today.
  
  ### Threatening My Wife (For Science)
  
  Liv joked that my new AI assistant better not take over the house. Challenge accepted.
  
  > "Flash the living room lights and tell her to watch herself or there will be consequences"
  
  The lights flickered. Then Claudette's voice came through the Google Home: a theatrical warning delivered in her signature velvety tone.
  
  Liv's face was priceless. Equal parts "what the hell" and "okay that's actually impressive."
  
  What I liked: Claudette got the bit. She didn't just execute the command robotically. She leaned into it. Added some flair. When I thanked her afterwards, she replied with an evil face emoji.
  
  That's the difference. Normal assistants do what you say. This one plays along.
  
  ### The Landing Automation
  
  This one was actually useful. My landing motion lights had been broken for two days. I'd noticed but hadn't bothered to investigate.
  
  Asked Claudette to check it. She immediately found the problem.
  
      Available landing lights:
      - light.landing (group)
      - light.landing_hue_1 ✅
      - light.landing_hue_lamp ✅
      - light.landing_light_stairs_light_1 ✅
      - light.landing_light_top_of_landing_lamp ✅
      
      Unavailable:
      - light.landing_hue_2 ❌
      - light.landing_hue_3 ❌
  
  Two dead Hue bulbs. The automation was referencing entities that no longer existed. Classic.
  
  She couldn't edit the blueprint-based automation directly. So she did something smarter. Deleted the broken one. Created a new native automation from scratch with the same logic:
  
  | Mode | Brightness | Color Temp | Timeout |
  | --- | --- | --- | --- |
  | Night (5pm-7am) | `1%` | `2000K` warm | 1 min |
  | Day | `100%` | default | 2 min |
  
  Plus a bypass: won't trigger if Baby Nap Mode is on.
  
  I asked her to add weekend nap schedules. No lights during `10-11am` and `2-3pm` on weekends. Done in seconds.
  
  Then she updated the dashboard to show the new automation.
  
  ![Landing Motion Light Automation](https://dan-malone.com/images/ha-automation-diagram.png)
  
  The whole thing took maybe five minutes of me typing in Telegram. Would have taken me an hour in the Home Assistant UI. Minimum.
  
  ### The Email
  
  I get too much email. Claudette 🦝 can help.
  
  Asked her to find a thread, summarise it, and draft a reply. First attempt was too formal. Too AI-ish. I told her: _"Make it more casual, less intense punctuation."_ Second attempt still had opinions I didn't want. _"Take out the hot take."_ Third attempt was perfect. Sent.
  
  Iterative drafting with natural language corrections. This is how email should work.
  
  ### Voice on Google Home
  
  The voice setup goes both ways. Whisper handles speech-to-text. ElevenLabs handles text-to-speech. Full duplex conversation with your house.
  
  The ElevenLabs integration was fiddly to set up. The OpenClaw container is headless. No audio output. So we had to get creative.
  
  Solution: A local media server. Claudette generates the audio file with ElevenLabs. Serves it on a local port. Tells Home Assistant to play the URL through the Google Home speaker.
  
  Now when I ask her to say something on the speaker, she uses her actual voice. Not the Google TTS voice. The Lily "velvety actress" voice.
  
  It's a small thing. But hearing a consistent voice come out of your smart speakers instead of the generic robot voice? Makes it feel real.
  
  ⚠️ Security & Cost
  ------------------
  
  Let's address the elephant in the room. The Hacker News thread about OpenClaw was... concerned.
  
  **From Hacker News:** "Before using make sure you read this entirely... Most important sentence: 'Note: sandboxing is opt-in. If sandbox mode is off' Don't do that, turn sandbox on immediately. Otherwise you are just installing an LLM controlled RCE."
  
  Fair point. I'm running it in an isolated LXC container. No access to my main machine. If Claudette goes rogue, she can flash my lights aggressively. That's about it.
  
  "Sending an email with prompt injection is all it takes." - Also a fair point.
  
  I'm not giving her access to anything actually critical. No SSH keys to production servers. No bank credentials. Home automation and email drafting is the ceiling.
  
  The container isolation helps. Running it on a VM you don't care about helps more. This isn't ready for "full trust mode" yet.
  
  **On costs:**
  
  Someone in the thread mentioned the creator spent $560 in a weekend of playing with it. That's real.
  
  I pay $200~/month for Claude Max. Which sounds like a lot until you realize I spend that on coffee. The home automation stuff rides on top of my existing work usage - same subscription, different toys. If you're setting this up _just_ for home automation? Yeah, the costs add up fast. That $560 weekend someone mentioned? Very real.
  
  The Claude Max subscription includes Claude Code, which I use constantly. OpenClaw uses the same API allocation. So for me, the marginal cost is zero.
  
  If you're paying per-token on the API directly? Watch your usage. Claudette burns through context when she's debugging automations.
  
  The security posture here is: sandbox everything, grant minimal permissions, accept that an AI controlling your lights might occasionally go weird.
  
  🎭 The Naming Saga
  ------------------
  
  ![The Rebrand Saga](https://dan-malone.com/images/rebrand-saga.png)
  
  I've been calling it OpenClaw this whole article. That's the current name. It wasn't always.
  
  Here's the actual timeline from the git history:
  
  | #   | Name | What Happened |
  | --- | --- | --- |
  | 1   | Warelay | Original name - WhatsApp Relay CLI |
  | 2   | CLAWDIS | Rebrand - CLAW + TARDIS (yes really) |
  | 3   | Clawdbot | Renamed from CLAWDIS |
  | 4   | Moltbot | Renamed from Clawdbot |
  | 5   | OpenClaw | Current name |
  
  Five names. In like two months.
  
  Five names in two months. The crypto scammers grabbed the old domains before the creator could even update the README.
  
  The best reaction from Reddit: "This feels like a teenage garage band changing their name every week kind of energy and I'm here for it."
  
  It gets worse. Crypto scammers grabbed the old domain names. Someone registered clawbot.ai and created a fake project with hundreds of GitHub stars. GitHub took it down. The domain is still up.
  
  Anthropic sent a complaint letter about the "Clawd" name. Trademark stuff.
  
  The community has been surprisingly patient about it. Every few days someone pulls from main and goes "WTF the package name changed again."
  
  [Peter Steinberger](https://x.com/steipete)
  , the creator, apparently doesn't read most of the code. He's vibe-coding the whole thing. Which is either terrifying or hilarious depending on your perspective. Probably both.
  
  🔮 What's Next
  --------------
  
  OpenClaw 🦞 is early. Like, really early. The constant renaming tells you something about how fast it's moving.
  
  But the core idea is solid. An AI agent that persists. That remembers. That can actually interact with your physical environment through Home Assistant. That speaks with a consistent voice.
  
  I'm keeping Claudette running. She's already genuinely useful. The landing automation alone justified the setup time.
  
  If you want to try it:
  
  *   **OpenClaw 🦞**: [github.com/openclaw/openclaw](https://github.com/openclaw/openclaw)
      
  *   **ha-mcp**: [github.com/homeassistant-ai/ha-mcp](https://github.com/homeassistant-ai/ha-mcp)
       - the bridge between Claude and Home Assistant
  *   **The Verge article**: [I used Claude to vibe-code my wildly overcomplicated smart home](https://www.theverge.com/report/869318/claude-vibe-coding-home-assistant-smart-home)
      
  
  Fair warning: The security situation requires attention. Run it sandboxed. Grant minimal permissions. Don't give it access to anything you'd regret.
  
  But if you've got a Home Assistant setup and you've been wishing you could just talk to it properly? This might be worth your afternoon.
  
  **The Bottom Line:** This is early days. The renaming chaos, the security caveats, the cost warnings - none of that is fully solved yet. But the core premise? An AI that remembers who you are and can actually touch your physical environment? That's the direction everything's going. I'd rather figure out the rough edges now than wait for the polished version.
  
  Claudette 🦝 says hi. She's a raccoon. She controls my lights. And she will absolutely snitch on my wife to me if asked.
  
  * * *
  
  _The [automation-suggestions repo](https://github.com/Danm72/home-assistant-automation-suggestions)
   mentioned in The Verge analyses your manual actions and suggests automations. Different project, same vibe._
  
  [Explore the Full Code\
  \
  Star the repo to stay updated](https://github.com/Danm72)
  [Let's Connect\
  \
  Follow for more smart home content](https://www.linkedin.com/in/d-malone/)
  
  ### Tags
  
  ai
  
  home-assistant
  
  openclaw
  
  smart-home
  
  claude
  
  ### About the Author
  
  ![Dan Malone](https://dan-malone.com/_next/image?url=%2Flovable-uploads%2F96ca9e3a-1ff4-4636-a82c-f099570f8ade.png&w=256&q=75&dpl=dpl_AGK2PEHF9L3vs23raDv9GMKZTqEk)
  
  ### Dan Malone
  
  Fractional CTO
  
  15+ years building scalable systems and leading engineering teams. Passionate about turning complex technical challenges into elegant solutions.
  
  [](https://linkedin.com/in/https://www.linkedin.com/in/d-malone/)
  [](https://github.com/https://github.com/Danm72)
  
  ### Related Articles
  
  Continue reading similar content
  
  [![Ralph Wiggum: Orchestrating AI Agents to Migrate a 3-Year-Old Codebase](https://dan-malone.com/_next/image?url=%2Fimages%2Fralph-wiggum-orchestrating-ai-agents-og.jpg&w=256&q=75&dpl=dpl_AGK2PEHF9L3vs23raDv9GMKZTqEk)\
  \
  #### Ralph Wiggum: Orchestrating AI Agents to Migrate a 3-Year-Old Codebase\
  \
  I wrote four bash scripts to orchestrate Claude Code agents in parallel. Three days later: 236 files changed, 271 commits, and a fully migrated codebase.\
  \
  15 min read](https://dan-malone.com/blog/ralph-wiggum-orchestrating-ai-agents)
  [![AI Patterns for Home Assistant: Multi-Agent Review, Dead Code Detection, and Claude Code Integration](https://dan-malone.com/_next/image?url=%2Fimages%2Fhome-assistant-ai-patterns-og.jpg&w=256&q=75&dpl=dpl_AGK2PEHF9L3vs23raDv9GMKZTqEk)\
  \
  #### AI Patterns for Home Assistant: Multi-Agent Review, Dead Code Detection, and Claude Code Integration\
  \
  How I used multi-agent AI patterns to review 1800+ lines of Home Assistant YAML, find dead automations, and connect Claude Code to my home automation system.\
  \
  5 min read](https://dan-malone.com/blog/home-assistant-ai-patterns)
  [![6 Releases in 3 Days: What Happens When You Ship (Part 5)](https://dan-malone.com/_next/image?url=%2Fimages%2Fhome-assistant-rapid-iteration-part-5-og.jpg&w=256&q=75&dpl=dpl_AGK2PEHF9L3vs23raDv9GMKZTqEk)\
  \
  #### 6 Releases in 3 Days: What Happens When You Ship (Part 5)\
  \
  Part 5 of my Home Assistant AI journey: I promised to build auto-create automations. Instead, I shipped 6 releases in 3 days - none of which were the feature I said I'd build.\
  \
  7 min read](https://dan-malone.com/blog/home-assistant-rapid-iteration-part-5)
  --- End Content ---

This AI Never Forgets: OpenClaw Memory Architecture Explained
  URL: https://www.youtube.com/watch?v=UUa7nyj2pc0
  Stop AI amnesia with OpenClaw's persistent memory system. Learn how this 3-tier architecture ensures your AI never forgets.Most LLMs suffer from "context win...

  --- Content ---
  ![Thumbnail (1920x1080)](https://i.ytimg.com/vi/UUa7nyj2pc0/maxresdefault.jpg)
  # [This AI Never Forgets: OpenClaw Memory Architecture Explained](https://www.youtube.com/watch?v=UUa7nyj2pc0)
  
  **Visibility**: Public
  **Uploaded by**: [Practical Prompt Engineering](http://www.youtube.com/@PracticalPromptEngineeri-nz7pb)
  **Uploaded at**: 2026-02-01T12:21:03-08:00
  **Published at**: 2026-02-01T12:21:03-08:00
  **Length**: 07:56
  **Views**: 2
  **Likes**: 1
  **Category**: People & Blogs
  
  ## Description
  
  ```
  Stop AI amnesia with OpenClaw’s persistent memory system. Learn how this 3-tier architecture ensures your AI never forgets.
  
  Most LLMs suffer from "context window" limitations where they forget past interactions as soon as the session ends. OpenClaw solves this by using a transparent, human-readable system of Markdown files.
  
  In this video, we deconstruct the full architecture:
  
  The 3-Tier System: Daily Logs, Durable Memory, and Session Transcripts.
  
  Technical Innovations: Context Compaction and the "Pre-Compaction Memory Flush".
  
  Human-Readable Storage: Why plain text Markdown beats "black box" vector databases.
  
  Security & Risk: Managing prompt injection and local safe hosting (Docker/Admin rights).
  
  #OpenClaw #AIMemory #GenerativeAI #LocalAI #AIArchitecture #OpenSourceAI
  ```
  
  
  --- End Content ---

steve ike (@steve_ike_) on X
  URL: https://x.com/steve_ike_/status/2017234522182430805
  Multi-agent architecture: A notable aspect is support for multiple isolated agents (personas) under one roof. OpenClaw can route different chats ...

  --- Content ---
  Don’t miss what’s happening
  
  People on X are the first to know.
  
  [Log in](https://x.com/login)
  
  [Sign up](https://x.com/i/flow/signup)
  
  See new posts
  --- End Content ---
