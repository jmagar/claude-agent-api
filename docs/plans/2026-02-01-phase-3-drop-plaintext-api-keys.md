# Phase 3: Drop Plaintext API Key Columns - Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Safely remove plaintext `owner_api_key` columns from `sessions` and `assistants` tables after Phase 2 verification period.

**Architecture:** Create irreversible database migration that drops plaintext columns and associated indexes, update SQLAlchemy models to remove deprecated fields, and verify system integrity post-migration.

**Tech Stack:** Alembic (migrations), SQLAlchemy (models), PostgreSQL (database), pytest (testing)

---

## ‚ö†Ô∏è CRITICAL PRE-DEPLOYMENT CHECKLIST

**DO NOT PROCEED unless ALL conditions are met:**

- [ ] Phase 2 code has been deployed to production for **7+ days minimum**
- [ ] Zero authentication failures in production logs (check `ownership_check_failed` events)
- [ ] Hash consistency verification passes: `uv run python scripts/verify_hash_consistency.py` exits with code 0
- [ ] Database backup created and verified restorable
- [ ] Rollback plan documented and tested in staging
- [ ] Stakeholder approval obtained (this is irreversible)

**Risk Level:** üî¥ **HIGH** - This migration is **IRREVERSIBLE**. Plaintext API keys will be permanently lost.

---

## Pre-Implementation Verification

### Task 0: Verify Phase 2 Stability and Capture Baseline

**Files:**
- Execute: `scripts/verify_hash_consistency.py`
- Review: Production logs from past 7 days
- Create: `.docs/phase3-baseline-metrics.md`

**Step 0: Capture baseline performance metrics**

```bash
# Query performance baseline
psql $DATABASE_URL <<EOF
\timing on
EXPLAIN ANALYZE SELECT * FROM sessions
WHERE owner_api_key_hash = 'sample_hash' LIMIT 10;

EXPLAIN ANALYZE SELECT * FROM assistants
WHERE owner_api_key_hash = 'sample_hash' LIMIT 10;
EOF

# API metrics (7-day averages)
# - p50/p95/p99 latency
# - Error rate
# - Authentication success rate
docker compose logs api --since 7d | grep "request_duration" | \
  awk '{print $5}' | sort -n | \
  awk 'BEGIN{c=0;sum=0} {a[c++]=$1;sum+=$1} END{print "p50:",a[int(c*0.5)],"p95:",a[int(c*0.95)],"p99:",a[int(c*0.99)]}'

# Cache hit ratio
redis-cli INFO stats | grep keyspace_hits
```

**Expected Output:** Document in `.docs/phase3-baseline-metrics.md`:

```markdown
# Phase 3 Baseline Metrics (Pre-Migration)

**Query Performance:**
- Sessions ownership check: ~15ms (p95)
- Assistants ownership check: ~12ms (p95)

**API Performance:**
- p50 latency: 50ms
- p95 latency: 200ms
- p99 latency: 500ms

**Error Rates:**
- Overall error rate: 0.05%
- Auth failure rate: 0.00%

**Cache Performance:**
- Hit ratio: 92%
- Keyspace hits: 125,450
```

**Step 1: Run hash consistency verification**

```bash
export DATABASE_URL="postgresql://user:pass@host:port/dbname"
uv run python scripts/verify_hash_consistency.py
```

**Expected Output:**
```
Checking sessions table...
‚úì All 1,234 sessions have matching hashes

Checking assistants table...
‚úì All 56 assistants have matching hashes

‚úì SUCCESS: All hashes are consistent with plaintext values
```

**Exit Code:** 0 (success)

**If Exit Code 1:** DO NOT PROCEED. Investigate hash mismatches before continuing.

**Step 1.5: Verify Phase 2 code is deployed to production**

```bash
# Method 1: Check git commit hash in production
ssh prod-api-server 'cd /app && git rev-parse HEAD'
# Compare with Phase 2 branch: git rev-parse fix/critical-security-and-performance-issues

# Method 2: Check application logs for hash-based operations
docker compose logs api --since 1h | grep "owner_api_key_hash" | wc -l
# Expected: >0 (Phase 2 code uses hashed keys)

# Method 3: Inspect database for hash column usage
psql $DATABASE_URL -c "SELECT COUNT(*) FROM sessions WHERE owner_api_key_hash IS NOT NULL;"
# Expected: Should match total sessions with owner_api_key
```

**Expected Output:** Git commit matches Phase 2 branch, logs show hash usage, database has populated hash columns.

**If Mismatch:** DO NOT PROCEED. Deploy Phase 2 code first and wait 7+ days.

**Step 2: Review production authentication logs**

```bash
# Check for any ownership check failures in past 7 days
docker compose logs api --since 7d | grep "ownership_check_failed" | wc -l
```

**Expected Output:** `0` (zero failures)

**If Non-Zero:** Investigate authentication issues before proceeding.

**Step 2.5: Analyze query performance impact**

```bash
# Get current query plans for ownership checks
psql $DATABASE_URL <<EOF
-- Sessions query plan (before Phase 3)
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM sessions
WHERE owner_api_key_hash = encode(digest('test-key', 'sha256'), 'hex')
LIMIT 10;

-- Verify index is being used
\d sessions
-- Should show both idx_sessions_owner_api_key AND idx_sessions_owner_api_key_hash

-- Check index usage stats
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE tablename IN ('sessions', 'assistants')
ORDER BY idx_scan DESC;
EOF
```

**Expected Output:**
- Both indexes exist and are being used
- Hash index has high idx_scan count (Phase 2 uses it)
- Query plan shows "Index Scan using idx_sessions_owner_api_key_hash"

**Step 3: Create database backup**

```bash
# Create timestamped backup before irreversible changes
pg_dump -h localhost -p 54432 -U postgres -d claude_agent_api \
  -F c -f backup_before_phase3_$(date +%Y%m%d_%H%M%S).dump

# Verify backup is restorable (test in isolated environment)
pg_restore --list backup_before_phase3_*.dump | head -20
```

**Expected Output:** Backup file created, table list shows `sessions` and `assistants` tables with both columns.

**Step 3.5: Configure monitoring alerts**

Create: `.docs/phase3-alerts.yaml`

```yaml
# Phase 3 Monitoring Alerts Configuration

alerts:
  - name: api_key_auth_failures
    metric: ownership_check_failed
    threshold: 5
    window: 5m
    severity: critical
    description: Detect authentication failures after Phase 3 deployment

  - name: database_query_latency_spike
    metric: query_duration_p95
    threshold: 500ms
    baseline: 200ms
    window: 10m
    severity: high
    description: Alert on query performance degradation

  - name: api_error_rate_increase
    metric: http_errors_5xx
    threshold: 1%
    window: 5m
    severity: high
    description: Detect API errors during migration
```

**Expected Output:** Alert configuration ready for production deployment.

**Step 4: Document rollback plan**

Create `docs/rollback-phase3.md` with emergency recovery procedure (see below).

---

## Implementation Tasks

### Task 1: Create Phase 3 Alembic Migration

**Files:**
- Create: `alembic/versions/20260208_000007_drop_plaintext_api_keys.py`

**Step 1: Generate migration template**

```bash
uv run alembic revision -m "drop plaintext api keys"
```

**Expected Output:**
```
Generating /path/to/alembic/versions/20260208_000007_drop_plaintext_api_keys.py ... done
```

**Step 2: Write migration upgrade function**

Edit the generated file:

```python
"""Drop plaintext API key columns after Phase 2 verification.

IRREVERSIBLE MIGRATION: This migration permanently removes plaintext API keys.

Pre-Deployment Checklist:
1. Phase 2 code deployed and verified for 7+ days
2. Hash consistency verification passed (scripts/verify_hash_consistency.py)
3. Database backup created and verified
4. Zero authentication failures in production logs
5. Stakeholder approval obtained

Revision ID: 20260208_000007
Revises: 20260201_000006
Create Date: 2026-02-08 00:00:07
"""

from collections.abc import Sequence

import sqlalchemy as sa

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "20260208_000007"
down_revision: str | None = "20260201_000006"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Drop plaintext owner_api_key columns and indexes.

    WARNING: This is an IRREVERSIBLE operation. Plaintext API keys will be
    permanently lost. Only the SHA-256 hashes in owner_api_key_hash will remain.

    Phase 3: Final cleanup after Phase 2 verification period.
    """
    # Set transaction timeout to prevent long-running locks
    # This ensures the migration completes quickly or fails fast
    op.execute("SET LOCAL statement_timeout = '30s'")

    # Drop indexes on plaintext columns first (required before dropping columns)
    op.drop_index("idx_sessions_owner_api_key", table_name="sessions")
    op.drop_index("idx_assistants_owner_api_key", table_name="assistants")

    # Drop plaintext columns (IRREVERSIBLE - data loss!)
    op.drop_column("sessions", "owner_api_key")
    op.drop_column("assistants", "owner_api_key")


def downgrade() -> None:
    """Attempt to restore plaintext columns.

    WARNING: This downgrade is LOSSY. Original plaintext API keys cannot be
    recovered from SHA-256 hashes. This downgrade will:

    1. Recreate owner_api_key columns (but they will be NULL)
    2. Recreate indexes (on NULL columns - not useful)

    Effect: All API keys will be lost. Clients must regenerate API keys.
    Ownership associations will be preserved via owner_api_key_hash.

    This downgrade exists only for schema consistency, not data recovery.
    """
    # Recreate plaintext columns (nullable, will be NULL for all rows)
    op.add_column(
        "sessions",
        sa.Column("owner_api_key", sa.String(255), nullable=True),
    )
    op.add_column(
        "assistants",
        sa.Column("owner_api_key", sa.String(255), nullable=True),
    )

    # Recreate indexes on NULL columns (not particularly useful)
    op.create_index("idx_sessions_owner_api_key", "sessions", ["owner_api_key"])
    op.create_index("idx_assistants_owner_api_key", "assistants", ["owner_api_key"])

    # NOTE: Plaintext API keys are NOT restored. They are permanently lost.
    # Client applications must regenerate API keys after this downgrade.
```

**Step 3: Verify migration syntax**

```bash
uv run alembic check
```

**Expected Output:**
```
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
```

**Step 4: Commit migration file**

```bash
git add alembic/versions/20260208_000007_drop_plaintext_api_keys.py
git commit -m "feat(migration): add Phase 3 migration to drop plaintext API keys

BREAKING CHANGE: This migration is IRREVERSIBLE and permanently removes
plaintext owner_api_key columns from sessions and assistants tables.

Only deploy after Phase 2 verification period (7+ days).

Pre-deployment checklist:
- Phase 2 code verified in production
- Hash consistency verification passed
- Database backup created
- Zero authentication failures
- Stakeholder approval obtained"
```

---

### Task 2: Update Session Model

**Files:**
- Modify: `apps/api/models/session.py:61-62` (remove owner_api_key column)
- Modify: `apps/api/models/session.py:95-104` (remove plaintext index)

**Step 1: Write failing test for model without owner_api_key**

Create: `tests/unit/models/test_session_phase3.py`

```python
"""Unit tests for Session model after Phase 3 migration."""

import pytest
from sqlalchemy import inspect


def test_session_model_has_only_hash_column() -> None:
    """Session model should only have owner_api_key_hash, not owner_api_key."""
    from apps.api.models.session import Session

    # Get model columns
    mapper = inspect(Session)
    column_names = {col.key for col in mapper.columns}

    # Should have hash column
    assert "owner_api_key_hash" in column_names

    # Should NOT have plaintext column (Phase 3 removes it)
    assert "owner_api_key" not in column_names


def test_session_model_indexes_only_hash() -> None:
    """Session model should only index owner_api_key_hash."""
    from apps.api.models.session import Session

    # Get table indexes
    index_names = {idx.name for idx in Session.__table__.indexes}

    # Should have hash index
    assert "idx_sessions_owner_api_key_hash" in index_names

    # Should NOT have plaintext index (Phase 3 removes it)
    assert "idx_sessions_owner_api_key" not in index_names
```

**Step 2: Run test to verify it fails**

```bash
uv run pytest tests/unit/models/test_session_phase3.py -v
```

**Expected Output:**
```
FAILED test_session_model_has_only_hash_column - AssertionError: assert 'owner_api_key' not in column_names
FAILED test_session_model_indexes_only_hash - AssertionError: assert 'idx_sessions_owner_api_key' not in index_names
```

**Step 3: Remove owner_api_key column from Session model**

Edit `apps/api/models/session.py`:

```python
# REMOVE THESE LINES (around line 61):
# owner_api_key: Mapped[str | None] = mapped_column(String(255), nullable=True)

# KEEP THIS LINE (hash column remains):
owner_api_key_hash: Mapped[str | None] = mapped_column(String(64), nullable=True)
```

**Step 4: Remove plaintext index from __table_args__**

Edit `apps/api/models/session.py`:

```python
__table_args__ = (
    Index("idx_sessions_created_at", created_at.desc()),
    Index("idx_sessions_status_created", status, created_at.desc()),
    Index(
        "idx_sessions_parent",
        parent_session_id,
        postgresql_where=parent_session_id.isnot(None),
    ),
    # REMOVE THIS LINE:
    # Index("idx_sessions_owner_api_key", owner_api_key),

    # KEEP THIS LINE (hash index remains):
    Index("idx_sessions_owner_api_key_hash", owner_api_key_hash),
)
```

**Step 5: Run test to verify it passes**

```bash
uv run pytest tests/unit/models/test_session_phase3.py -v
```

**Expected Output:**
```
PASSED test_session_model_has_only_hash_column
PASSED test_session_model_indexes_only_hash
```

**Step 6: Refactor - Review code quality (DRY, KISS, naming)**

```bash
# Check for code duplication
grep -n "owner_api_key_hash" apps/api/models/session.py

# Verify naming conventions
grep -n "class Session" apps/api/models/session.py

# Ensure no hardcoded values
grep -n "String(64)" apps/api/models/session.py  # Hash length is appropriate
```

**Expected Output:** No issues found. Code is clean, follows conventions, and uses appropriate type sizes.

**Step 7: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======  # All tests pass, not just new ones
```

**If Failures:** Fix regressions before committing. Phase 3 changes should not break existing tests.

**Step 8: Commit model changes**

```bash
git add apps/api/models/session.py tests/unit/models/test_session_phase3.py
git commit -m "refactor(models): remove owner_api_key column from Session model (Phase 3)

Remove plaintext API key column and index after Phase 3 migration.
Only owner_api_key_hash column remains for authentication."
```

---

### Task 3: Update Assistant Model

**Files:**
- Modify: `apps/api/models/assistant.py:65-66` (remove owner_api_key column)
- Modify: `apps/api/models/assistant.py:75-79` (remove plaintext index)

**Step 1: Write failing test for Assistant model**

Create: `tests/unit/models/test_assistant_phase3.py`

```python
"""Unit tests for Assistant model after Phase 3 migration."""

import pytest
from sqlalchemy import inspect


def test_assistant_model_has_only_hash_column() -> None:
    """Assistant model should only have owner_api_key_hash, not owner_api_key."""
    from apps.api.models.assistant import Assistant

    # Get model columns
    mapper = inspect(Assistant)
    column_names = {col.key for col in mapper.columns}

    # Should have hash column
    assert "owner_api_key_hash" in column_names

    # Should NOT have plaintext column (Phase 3 removes it)
    assert "owner_api_key" not in column_names


def test_assistant_model_indexes_only_hash() -> None:
    """Assistant model should only index owner_api_key_hash."""
    from apps.api.models.assistant import Assistant

    # Get table indexes
    index_names = {idx.name for idx in Assistant.__table__.indexes}

    # Should have hash index
    assert "idx_assistants_owner_api_key_hash" in index_names

    # Should NOT have plaintext index (Phase 3 removes it)
    assert "idx_assistants_owner_api_key" not in index_names
```

**Step 2: Run test to verify it fails**

```bash
uv run pytest tests/unit/models/test_assistant_phase3.py -v
```

**Expected Output:**
```
FAILED test_assistant_model_has_only_hash_column - AssertionError: assert 'owner_api_key' not in column_names
FAILED test_assistant_model_indexes_only_hash - AssertionError: assert 'idx_assistants_owner_api_key' not in index_names
```

**Step 3: Remove owner_api_key column from Assistant model**

Edit `apps/api/models/assistant.py`:

```python
# REMOVE THIS LINE (around line 65):
# owner_api_key: Mapped[str | None] = mapped_column(String(255), nullable=True)

# KEEP THIS LINE (hash column remains):
owner_api_key_hash: Mapped[str | None] = mapped_column(String(64), nullable=True)
```

**Step 4: Remove plaintext index from __table_args__**

Edit `apps/api/models/assistant.py`:

```python
__table_args__ = (
    Index("idx_assistants_created_at", created_at.desc()),
    # REMOVE THIS LINE:
    # Index("idx_assistants_owner_api_key", owner_api_key),

    # KEEP THIS LINE (hash index remains):
    Index("idx_assistants_owner_api_key_hash", owner_api_key_hash),
)
```

**Step 5: Run test to verify it passes**

```bash
uv run pytest tests/unit/models/test_assistant_phase3.py -v
```

**Expected Output:**
```
PASSED test_assistant_model_has_only_hash_column
PASSED test_assistant_model_indexes_only_hash
```

**Step 6: Refactor - Review code consistency with Session model**

```bash
# Verify both models use same pattern
diff -u \
  <(grep "owner_api_key_hash" apps/api/models/session.py) \
  <(grep "owner_api_key_hash" apps/api/models/assistant.py)

# Both should use String(64), nullable=True
```

**Expected Output:** Pattern is consistent across models.

**Step 7: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 8: Commit model changes**

```bash
git add apps/api/models/assistant.py tests/unit/models/test_assistant_phase3.py
git commit -m "refactor(models): remove owner_api_key column from Assistant model (Phase 3)

Remove plaintext API key column and index after Phase 3 migration.
Only owner_api_key_hash column remains for authentication."
```

---

### Task 4: Update SessionRepository (Remove Plaintext References)

**Files:**
- Modify: `apps/api/adapters/session_repo.py:49-50` (create method - remove plaintext assignment)
- Review: All references to `session.owner_api_key` should only access hash

**Step 1: Write failing test for repository without plaintext**

Create: `tests/integration/test_session_repo_phase3.py`

```python
"""Integration tests for SessionRepository after Phase 3 migration."""

from uuid import uuid4

import pytest
from httpx import AsyncClient
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from apps.api.adapters.session_repo import SessionRepository
from apps.api.dependencies import get_db
from apps.api.models.session import Session
from apps.api.utils.crypto import hash_api_key


@pytest.fixture
async def db_session(_async_client: AsyncClient):
    """Get database session from initialized app."""
    agen = get_db()
    session = await anext(agen)
    try:
        yield session
    finally:
        await agen.aclose()


@pytest.mark.anyio
async def test_create_only_stores_hash(db_session: AsyncSession) -> None:
    """After Phase 3, create should only populate owner_api_key_hash."""
    repository = SessionRepository(db_session)
    session_id = uuid4()
    api_key = "test-key-phase3"

    # Create session
    await repository.create(
        session_id=session_id,
        model="sonnet",
        owner_api_key=api_key,
    )

    # Verify only hash column is populated
    stmt = select(Session).where(Session.id == session_id)
    result = await db_session.execute(stmt)
    session = result.scalar_one()

    # Hash column should be populated
    assert session.owner_api_key_hash is not None
    assert session.owner_api_key_hash == hash_api_key(api_key)

    # Plaintext column should NOT exist (Phase 3 removed it)
    assert not hasattr(session, "owner_api_key")
```

**Step 2: Run test to verify it fails**

```bash
uv run pytest tests/integration/test_session_repo_phase3.py::test_create_only_stores_hash -v
```

**Expected Output:**
```
FAILED - AssertionError: assert not hasattr(session, 'owner_api_key')
```

**Step 3: Remove plaintext column assignment from create method**

Edit `apps/api/adapters/session_repo.py`:

```python
async def create(
    self,
    session_id: UUID,
    model: str,
    working_directory: str | None = None,
    parent_session_id: UUID | None = None,
    metadata: dict[str, object] | None = None,
    owner_api_key: str | None = None,
) -> Session:
    """Create a new session.

    Args:
        owner_api_key: API key that owns this session.
                      If None, session is PUBLIC (visible to all API keys).

    Security Notes:
        - Public sessions (owner_api_key=None) bypass ownership checks
        - NULL owner_api_key indicates a globally accessible session
        - Private sessions require matching API key for access
    """
    # Phase 3: Only hash is stored, plaintext column no longer exists
    owner_api_key_hash = hash_api_key(owner_api_key) if owner_api_key else None

    session = Session(
        id=session_id,
        model=model,
        working_directory=working_directory,
        parent_session_id=parent_session_id,
        metadata_=metadata,
        # REMOVE THIS LINE (plaintext column no longer exists):
        # owner_api_key=owner_api_key,

        # KEEP THIS LINE (only hash is stored):
        owner_api_key_hash=owner_api_key_hash,
    )

    self.db.add(session)
    await self.db.flush()
    await self.db.refresh(session)

    return session
```

**Step 4: Run test to verify it passes**

```bash
uv run pytest tests/integration/test_session_repo_phase3.py::test_create_only_stores_hash -v
```

**Expected Output:**
```
PASSED test_create_only_stores_hash
```

**Step 5: Refactor - Verify no other methods use plaintext**

```bash
# Search for any remaining plaintext references in repository
grep -n "\.owner_api_key[^_]" apps/api/adapters/session_repo.py

# Should return empty (no matches)
```

**Expected Output:** (empty - no plaintext references found)

**If Matches Found:** Remove them. Only `owner_api_key_hash` should be accessed.

**Step 6: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 7: Commit repository changes**

```bash
git add apps/api/adapters/session_repo.py tests/integration/test_session_repo_phase3.py
git commit -m "refactor(repository): remove owner_api_key plaintext assignment (Phase 3)

SessionRepository.create() now only populates owner_api_key_hash.
Plaintext column has been removed from database schema."
```

---

### Task 5: Update SessionService (Remove Plaintext Access)

**Files:**
- Modify: `apps/api/services/session.py:772-777` (_enforce_owner method)
- Review: Ensure no other methods access `session.owner_api_key`

**Step 1: Write test for _enforce_owner using only hash**

Add to `tests/integration/test_session_service_hashing.py`:

```python
@pytest.mark.anyio
async def test_enforce_owner_uses_only_hash_phase3(
    db_session: AsyncSession,
) -> None:
    """After Phase 3, _enforce_owner should only use owner_api_key_hash."""
    from apps.api.services.session import SessionService
    from apps.api.models.session import Session as SessionModel
    from apps.api.utils.crypto import hash_api_key
    from uuid import uuid4

    service = SessionService()

    # Create mock session with only hash (no plaintext)
    session = SessionModel(
        id=uuid4(),
        model="sonnet",
        owner_api_key_hash=hash_api_key("test-key-123"),
    )

    # Should allow access with correct key
    current_api_key = "test-key-123"
    result = service._enforce_owner(session, current_api_key)
    assert result == session

    # Should raise with wrong key
    from apps.api.exceptions.session import SessionNotFoundError
    with pytest.raises(SessionNotFoundError):
        service._enforce_owner(session, "wrong-key")
```

**Step 2: Run test to verify current implementation**

```bash
uv run pytest tests/integration/test_session_service_hashing.py::test_enforce_owner_uses_only_hash_phase3 -v
```

**Expected Output:**
```
FAILED - AttributeError: 'Session' object has no attribute 'owner_api_key'
```

**Step 3: Update _enforce_owner to use only hash column**

Edit `apps/api/services/session.py`:

```python
def _enforce_owner(
    self,
    session: Session,
    current_api_key: str | None,
) -> Session:
    """Enforce that the current API key owns the session.

    Args:
        session: The session to check ownership for.
        current_api_key: The API key from the request (plaintext).

    Returns:
        The session if ownership check passes.

    Raises:
        SessionNotFoundError: If ownership check fails.

    Security Notes:
        - Public sessions (owner_api_key_hash=NULL) bypass ownership checks
        - Private sessions require hash match for access
        - Uses constant-time comparison to prevent timing attacks

    Phase 3 Changes:
        - Only uses owner_api_key_hash (plaintext column removed)
        - Hashes current_api_key for comparison
    """
    if current_api_key and session.owner_api_key_hash:
        # Phase 3: Hash the incoming API key and compare to stored hash
        request_hash = hash_api_key(current_api_key)
        if not secrets.compare_digest(session.owner_api_key_hash, request_hash):
            logger.warning(
                "ownership_check_failed",
                session_id=str(session.id),
                has_session_hash=True,
                has_request_key=True,
            )
            raise SessionNotFoundError(session.id)
    return session
```

**Step 4: Run test to verify it passes**

```bash
uv run pytest tests/integration/test_session_service_hashing.py::test_enforce_owner_uses_only_hash_phase3 -v
```

**Expected Output:**
```
PASSED test_enforce_owner_uses_only_hash_phase3
```

**Step 5: Refactor - Verify no other SessionService methods access owner_api_key**

```bash
# Search for any remaining plaintext references in service
grep -n "\.owner_api_key[^_]" apps/api/services/session.py
```

**Expected Output:** (empty - no matches)

**If Matches Found:** This is a critical bug. All plaintext access must be removed.

**Step 6: Refactor - Verify constant-time comparison is used**

```bash
# Ensure secrets.compare_digest is used (not ==)
grep -n "compare_digest" apps/api/services/session.py
```

**Expected Output:** Line showing `secrets.compare_digest(session.owner_api_key_hash, request_hash)`

**Security Check:** Using `==` would be vulnerable to timing attacks. `secrets.compare_digest()` prevents this.

**Step 7: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 8: Commit service changes**

```bash
git add apps/api/services/session.py tests/integration/test_session_service_hashing.py
git commit -m "refactor(service): update _enforce_owner to use only hash (Phase 3)

SessionService._enforce_owner() now only accesses owner_api_key_hash.
No references to plaintext owner_api_key column remain."
```

---

### Task 6A: Update Assistant Dataclass and Ownership Check

**Files:**
- Modify: `apps/api/services/assistants/assistant_service.py` (Assistant dataclass, _enforce_owner)
- Create: `tests/integration/test_assistant_service_phase3.py`

**Step 1: Write test for dataclass without plaintext**

Create: `tests/integration/test_assistant_service_phase3.py`

```python
"""Integration tests for AssistantService after Phase 3 migration."""

import pytest
from datetime import datetime, UTC

from apps.api.services.assistants import AssistantService, Assistant
from apps.api.utils.crypto import hash_api_key
from apps.api.exceptions.assistant import AssistantNotFoundError


@pytest.mark.anyio
async def test_enforce_owner_uses_only_hash() -> None:
    """After Phase 3, _enforce_owner should only use owner_api_key_hash."""
    service = AssistantService()

    # Create mock assistant with only hash (no plaintext)
    assistant = Assistant(
        id="asst_test123",
        model="gpt-4",
        created_at=datetime.now(UTC),
        updated_at=datetime.now(UTC),
        owner_api_key_hash=hash_api_key("test-key-456"),
    )

    # Should allow access with correct key
    result = service._enforce_owner(assistant, "test-key-456")
    assert result == assistant

    # Should raise with wrong key
    with pytest.raises(AssistantNotFoundError):
        service._enforce_owner(assistant, "wrong-key")
```

**Step 2: Run test to verify it fails**

```bash
uv run pytest tests/integration/test_assistant_service_phase3.py::test_enforce_owner_uses_only_hash -v
```

**Expected Output:**
```
FAILED - AttributeError: 'Assistant' object has no attribute 'owner_api_key_hash'
```

**Step 3: Update Assistant dataclass to remove plaintext**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
@dataclass
class Assistant:
    """Assistant data model."""

    id: str
    model: str
    created_at: datetime
    updated_at: datetime
    name: str | None = None
    description: str | None = None
    instructions: str | None = None
    tools: list[dict[str, object]] = field(default_factory=list)
    metadata: dict[str, str] = field(default_factory=dict)
    # REMOVE THIS LINE:
    # owner_api_key: str | None = None

    # KEEP THIS LINE (only hash remains):
    owner_api_key_hash: str | None = None

    temperature: float | None = None
    top_p: float | None = None
    response_format: dict[str, str] | None = None
```

**Step 4: Update _enforce_owner to use only hash**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
def _enforce_owner(
    self,
    assistant: Assistant,
    current_api_key: str | None,
) -> Assistant:
    """Enforce that the current API key owns the assistant.

    Phase 3: Only uses owner_api_key_hash (plaintext removed).
    """
    if current_api_key and assistant.owner_api_key_hash:
        # Hash the incoming API key and compare to stored hash
        request_hash = hash_api_key(current_api_key)
        if not secrets.compare_digest(assistant.owner_api_key_hash, request_hash):
            raise AssistantNotFoundError(assistant.id)
    return assistant
```

**Step 5: Run test to verify it passes**

```bash
uv run pytest tests/integration/test_assistant_service_phase3.py::test_enforce_owner_uses_only_hash -v
```

**Expected Output:**
```
PASSED test_enforce_owner_uses_only_hash
```

**Step 6: Refactor - Verify constant-time comparison and security**

```bash
# Ensure secrets.compare_digest is used (prevents timing attacks)
grep -n "compare_digest" apps/api/services/assistants/assistant_service.py

# Verify dataclass only has hash field
grep -n "owner_api_key" apps/api/services/assistants/assistant_service.py | grep -v "hash"
```

**Expected Output:**
- Line showing `secrets.compare_digest(assistant.owner_api_key_hash, request_hash)`
- Empty result for plaintext field (only hash field exists)

**Step 7: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 8: Commit dataclass and ownership changes**

```bash
git add apps/api/services/assistants/assistant_service.py tests/integration/test_assistant_service_phase3.py
git commit -m "refactor(service): update Assistant dataclass and _enforce_owner (Phase 3)

Remove owner_api_key field from Assistant dataclass.
Update _enforce_owner to hash incoming API keys for comparison."
```

---

### Task 6B: Update Assistant Cache Operations

**Files:**
- Modify: `apps/api/services/assistants/assistant_service.py` (_cache_assistant, delete_assistant)

**Step 1: Write test for cache using only hash**

Add to `tests/integration/test_assistant_service_phase3.py`:

```python
@pytest.mark.anyio
async def test_delete_assistant_uses_hash_for_cache() -> None:
    """After Phase 3, delete should only use hash for cache cleanup."""
    from unittest.mock import AsyncMock

    cache_mock = AsyncMock()
    service = AssistantService(cache=cache_mock)

    # Mock get_assistant to return assistant with only hash
    assistant = Assistant(
        id="asst_delete123",
        model="gpt-4",
        created_at=datetime.now(UTC),
        updated_at=datetime.now(UTC),
        owner_api_key_hash=hash_api_key("delete-key"),
    )
    service.get_assistant = AsyncMock(return_value=assistant)

    # Mock database deletion
    db_repo_mock = AsyncMock()
    db_repo_mock.delete = AsyncMock(return_value=True)
    service._db_repo = db_repo_mock

    # Delete assistant
    await service.delete_assistant("asst_delete123", "delete-key")

    # Verify cache operations used hashed key
    expected_hash = hash_api_key("delete-key")
    expected_index_key = f"assistant:owner:{expected_hash}"

    cache_mock.remove_from_set.assert_called_once_with(
        expected_index_key,
        "asst_delete123"
    )
```

**Step 2: Update _cache_assistant to use hash**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
async def _cache_assistant(self, assistant: Assistant) -> None:
    """Cache an assistant in Redis.

    Phase 3: Uses owner_api_key_hash for cache indexes.
    """
    if not self._cache:
        return

    key = self._cache_key(assistant.id)
    data: dict[str, JsonValue] = {
        "id": assistant.id,
        "model": assistant.model,
        "name": assistant.name,
        "description": assistant.description,
        "instructions": assistant.instructions,
        "tools": cast("list[JsonValue]", assistant.tools),
        "metadata": cast("dict[str, JsonValue]", assistant.metadata),
        # REMOVE THIS LINE:
        # "owner_api_key": assistant.owner_api_key,

        # KEEP THIS LINE:
        "owner_api_key_hash": assistant.owner_api_key_hash,

        "temperature": assistant.temperature,
        "top_p": assistant.top_p,
        "created_at": assistant.created_at.isoformat(),
        "updated_at": assistant.updated_at.isoformat(),
    }

    await self._cache.set_json(key, data, self._ttl)

    # Phase 3: Add to hashed owner index (use hash directly)
    if assistant.owner_api_key_hash:
        owner_index_key = f"assistant:owner:{assistant.owner_api_key_hash}"
        await self._cache.add_to_set(owner_index_key, assistant.id)
```

**Step 3: Update delete_assistant to use hash**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
async def delete_assistant(
    self,
    assistant_id: str,
    _current_api_key: str | None = None,
) -> bool:
    """Delete an assistant.

    Phase 3: Uses owner_api_key_hash for cache cleanup.
    """
    # Get assistant to extract owner_api_key_hash before deletion
    assistant = await self.get_assistant(assistant_id, _current_api_key)

    # Delete from database first
    if self._db_repo:
        deleted = await self._db_repo.delete(assistant_id)
        if not deleted:
            return False

    # Delete from cache
    if self._cache:
        key = self._cache_key(assistant_id)
        await self._cache.delete(key)

        # Phase 3: Remove from hashed owner index (use hash, not plaintext)
        if assistant and assistant.owner_api_key_hash:
            owner_index_key = f"assistant:owner:{assistant.owner_api_key_hash}"
            await self._cache.remove_from_set(owner_index_key, assistant_id)

    logger.info("Assistant deleted", assistant_id=assistant_id)
    return True
```

**Step 4: Run tests to verify changes**

```bash
uv run pytest tests/integration/test_assistant_service_phase3.py::test_delete_assistant_uses_hash_for_cache -v
```

**Expected Output:**
```
PASSED test_delete_assistant_uses_hash_for_cache
```

**Step 5: Refactor - Verify cache keys use consistent patterns**

```bash
# Check all cache key patterns use hash
grep -n "assistant:owner:" apps/api/services/assistants/assistant_service.py

# Verify no plaintext in cache data
grep -n '"owner_api_key":' apps/api/services/assistants/assistant_service.py
```

**Expected Output:**
- All cache keys use `f"assistant:owner:{owner_api_key_hash}"` pattern
- Empty result for plaintext in cache (only hash is cached)

**Step 6: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 7: Commit cache operation changes**

```bash
git add apps/api/services/assistants/assistant_service.py tests/integration/test_assistant_service_phase3.py
git commit -m "refactor(service): update Assistant cache operations (Phase 3)

Update _cache_assistant and delete_assistant to use owner_api_key_hash.
Cache indexes now use hash values directly."
```

---

### Task 6C: Update Assistant Creation and Mapping

**Files:**
- Modify: `apps/api/services/assistants/assistant_service.py` (create_assistant, _parse_cached_assistant, _map_db_to_service)

**Step 1: Update create_assistant to populate only hash**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
async def create_assistant(
    self,
    model: str,
    name: str | None = None,
    description: str | None = None,
    instructions: str | None = None,
    tools: list[dict[str, object]] | None = None,
    metadata: dict[str, str] | None = None,
    owner_api_key: str | None = None,
    temperature: float | None = None,
    top_p: float | None = None,
) -> Assistant:
    """Create a new assistant.

    Phase 3: Only populates owner_api_key_hash (plaintext removed).
    """
    assistant_id = generate_assistant_id()
    now = datetime.now(UTC)
    tools_list = tools if tools is not None else []
    metadata_dict = metadata if metadata is not None else {}

    # Phase 3: Only hash is stored
    owner_api_key_hash = hash_api_key(owner_api_key) if owner_api_key else None

    assistant = Assistant(
        id=assistant_id,
        model=model,
        name=name,
        description=description,
        instructions=instructions,
        tools=tools_list,
        metadata=metadata_dict,
        # REMOVE THIS LINE:
        # owner_api_key=owner_api_key,

        # KEEP THIS LINE:
        owner_api_key_hash=owner_api_key_hash,

        temperature=temperature,
        top_p=top_p,
        created_at=now,
        updated_at=now,
    )

    # ... rest of method unchanged
```

**Step 2: Update _parse_cached_assistant**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
def _parse_cached_assistant(
    self,
    parsed: dict[str, JsonValue],
) -> Assistant | None:
    """Parse cached assistant data into Assistant object.

    Phase 3: Only reads owner_api_key_hash from cache.
    """
    try:
        # ... timestamp parsing unchanged ...

        return Assistant(
            id=str(parsed["id"]),
            model=str(parsed["model"]),
            name=str(parsed["name"]) if parsed.get("name") else None,
            description=str(parsed["description"]) if parsed.get("description") else None,
            instructions=str(parsed["instructions"]) if parsed.get("instructions") else None,
            tools=tools,
            metadata=metadata,
            # REMOVE THIS LINE:
            # owner_api_key=str(parsed["owner_api_key"]) if parsed.get("owner_api_key") else None,

            # KEEP THIS LINE:
            owner_api_key_hash=str(parsed["owner_api_key_hash"]) if parsed.get("owner_api_key_hash") else None,

            temperature=float(str(parsed["temperature"])) if parsed.get("temperature") else None,
            top_p=float(str(parsed["top_p"])) if parsed.get("top_p") else None,
            created_at=created_at,
            updated_at=updated_at,
        )
    except (KeyError, ValueError, TypeError) as e:
        logger.warning("Failed to parse cached assistant", error=str(e))
        return None
```

**Step 3: Update _map_db_to_service**

Edit `apps/api/services/assistants/assistant_service.py`:

```python
def _map_db_to_service(self, db_assistant: DbAssistant) -> Assistant:
    """Map database assistant to service assistant.

    Phase 3: Only reads owner_api_key_hash from database.
    """
    return Assistant(
        id=db_assistant.id,
        model=db_assistant.model,
        name=db_assistant.name,
        description=db_assistant.description,
        instructions=db_assistant.instructions,
        tools=db_assistant.tools,
        metadata=db_assistant.metadata_ or {},
        # REMOVE THIS LINE:
        # owner_api_key=db_assistant.owner_api_key,

        # KEEP THIS LINE:
        owner_api_key_hash=db_assistant.owner_api_key_hash,

        temperature=db_assistant.temperature,
        top_p=db_assistant.top_p,
        created_at=db_assistant.created_at,
        updated_at=db_assistant.updated_at,
    )
```

**Step 4: Run all AssistantService tests**

```bash
uv run pytest tests/integration/test_assistant_service_phase3.py -v
```

**Expected Output:**
```
PASSED test_enforce_owner_uses_only_hash
PASSED test_delete_assistant_uses_hash_for_cache
```

**Step 5: Refactor - Verify complete plaintext removal**

```bash
# Final verification: No plaintext references anywhere in AssistantService
grep -n "owner_api_key[^_]" apps/api/services/assistants/assistant_service.py

# Should only find parameter names (owner_api_key: str | None), not field access
```

**Expected Output:** Only method parameter declarations (not `.owner_api_key` field access)

**If Field Access Found:** This is a critical bug. Remove all field access to plaintext.

**Step 6: Refactor - Verify DRY principle across parsing/mapping**

```bash
# Check for code duplication in mapping functions
diff -u \
  <(grep -A 5 "owner_api_key_hash" apps/api/services/assistants/assistant_service.py | grep "_parse_cached") \
  <(grep -A 5 "owner_api_key_hash" apps/api/services/assistants/assistant_service.py | grep "_map_db_to")

# Both should handle hash field consistently
```

**Expected Output:** Consistent pattern across all mapping functions.

**Step 7: Run full test suite to prevent regressions**

```bash
uv run pytest tests/ -v --tb=short
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 8: Commit creation and mapping changes**

```bash
git add apps/api/services/assistants/assistant_service.py
git commit -m "refactor(service): update Assistant creation and mapping (Phase 3)

Update create_assistant, _parse_cached_assistant, and _map_db_to_service
to use only owner_api_key_hash. All plaintext references removed."
```

---

### Task 7: Update Documentation

**Files:**
- Modify: `.docs/api-key-hashing-migration.md` (mark Phase 3 as complete)
- Create: `docs/rollback-phase3.md` (emergency recovery procedure)

**Step 1: Update migration guide**

Edit `.docs/api-key-hashing-migration.md`:

```markdown
### Phase 3: Drop Plaintext Column (COMPLETED)

‚úÖ **STATUS:** Migration deployed on YYYY-MM-DD

**Migration:** `20260208_000007_drop_plaintext_api_keys.py`

**Actions:**
1. Dropped `owner_api_key` column from `sessions` and `assistants` tables
2. Dropped indexes `idx_sessions_owner_api_key` and `idx_assistants_owner_api_key`
3. Updated SQLAlchemy models to remove plaintext column
4. Updated all services to use only `owner_api_key_hash`

**Verification:**
```bash
# Verify plaintext columns are gone
psql $DATABASE_URL -c "\d sessions"
psql $DATABASE_URL -c "\d assistants"
```

**State After Phase 3:**
- Only `owner_api_key_hash` column exists
- All authentication uses SHA-256 hash comparison
- Plaintext API keys are permanently removed
- Migration is IRREVERSIBLE

**Rollback:**
‚ö†Ô∏è **WARNING:** Phase 3 is irreversible. Plaintext API keys cannot be recovered.

If rollback is absolutely necessary, see: `docs/rollback-phase3.md`

Effect: All API keys will be lost. Clients must regenerate API keys.
```

**Step 2: Create rollback documentation**

Create: `docs/rollback-phase3.md`

```markdown
# Phase 3 Rollback Emergency Procedure

‚ö†Ô∏è **WARNING:** This is a LOSSY rollback. Original plaintext API keys cannot be recovered from SHA-256 hashes.

## When to Use This Procedure

Only use this if:
- Phase 3 migration causes critical production failure
- No other recovery option is available
- You accept that all API keys will be lost

**Effect:** All clients must regenerate API keys after rollback.

## Rollback Steps

### Step 1: Create Database Backup (Critical)

```bash
# Backup current state before rollback
pg_dump -h localhost -p 54432 -U postgres -d claude_agent_api \
  -F c -f backup_before_rollback_$(date +%Y%m%d_%H%M%S).dump
```

### Step 2: Run Alembic Downgrade

```bash
# Downgrade to Phase 2 (before plaintext columns were dropped)
uv run alembic downgrade 20260201_000006
```

**Effect:**
- Recreates `owner_api_key` column (but all values will be NULL)
- Recreates indexes on NULL column (not useful)
- Ownership information is preserved in `owner_api_key_hash`

### Step 3: Restore Phase 2 Application Code

```bash
# Checkout code from Phase 2 (before Phase 3 changes)
git revert <phase-3-commit-hash>

# Restart services
docker compose restart api
```

### Step 4: Generate New API Keys for All Clients

**Manual Process Required:**

1. Identify all client API keys from `owner_api_key_hash` values
2. Generate new API keys for each unique hash
3. Update `owner_api_key` column with new plaintext keys
4. Notify clients of new API keys
5. Update client configurations

**SQL to Generate New Keys:**

```sql
-- Generate UUIDs as new API keys
UPDATE sessions
SET owner_api_key = gen_random_uuid()::text
WHERE owner_api_key_hash IS NOT NULL;

UPDATE assistants
SET owner_api_key = gen_random_uuid()::text
WHERE owner_api_key_hash IS NOT NULL;
```

### Step 5: Communicate with Clients

**Email Template:**

```
Subject: URGENT: API Key Rotation Required

Due to an emergency database rollback, all API keys have been reset.

Your new API key: <new-key-here>

Please update your configuration immediately.

We apologize for the inconvenience.
```

### Step 6: Verify System Recovery

```bash
# Test authentication with new keys
curl -H "X-API-Key: <new-key>" http://localhost:54000/api/v1/sessions

# Check logs for successful authentication
docker compose logs api | grep "ownership_check"
```

## Prevention

**To avoid needing this rollback:**
- Thoroughly test Phase 3 in staging environment
- Wait 7+ days after Phase 2 deployment
- Verify hash consistency before Phase 3
- Monitor authentication logs during Phase 3 rollout
- Have database backups before Phase 3

## Post-Rollback Actions

1. **Root Cause Analysis:** Identify why Phase 3 failed
2. **Fix Issues:** Address problems before attempting Phase 3 again
3. **Extended Testing:** Test fix in staging for 2+ weeks
4. **Gradual Rollout:** Deploy Phase 3 to small percentage of traffic first
5. **Monitoring:** Enhanced monitoring for authentication failures

## Support

If you need assistance with this rollback:
- Check `#oncall-engineering` Slack channel
- Page on-call engineer via PagerDuty
- Escalate to CTO if critical production impact
```

**Step 3: Commit documentation updates**

```bash
git add .docs/api-key-hashing-migration.md docs/rollback-phase3.md
git commit -m "docs: update Phase 3 migration documentation

Mark Phase 3 as complete in migration guide.
Add emergency rollback procedure (lossy - API keys will be lost)."
```

---

### Task 8: Run Full Test Suite and Verify API Contract

**Files:**
- Execute: All tests
- Review: OpenAPI contract for breaking changes

**Step 1: Run all unit tests**

```bash
uv run pytest tests/unit -v
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 2: Run all integration tests**

```bash
uv run pytest tests/integration -v
```

**Expected Output:**
```
====== X passed in Y.YYs ======
```

**Step 3: Verify API contract compatibility**

```bash
# Compare API responses before and after Phase 3
# Ensure no breaking changes to external API contract

# Test session creation endpoint
curl -X POST http://localhost:54000/api/v1/sessions \
  -H "X-API-Key: test-key" \
  -H "Content-Type: application/json" \
  -d '{"model": "sonnet"}' | jq .

# Expected: Response should NOT include owner_api_key field
# Response should be identical to Phase 2 (no client-visible changes)

# Test assistant creation endpoint
curl -X POST http://localhost:54000/api/v1/assistants \
  -H "X-API-Key: test-key" \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4"}' | jq .

# Expected: Response should NOT include owner_api_key field
```

**Expected Output:** API responses identical to Phase 2. No `owner_api_key` in responses.

**Step 4: Run type checking**

```bash
uv run ty check
```

**Expected Output:**
```
Success: no issues found in X source files
```

**Step 5: Run linting**

```bash
uv run ruff check .
```

**Expected Output:**
```
All checks passed!
```

**Step 6: Commit if any test fixes needed**

```bash
# Only if tests revealed issues that were fixed
git add <fixed-files>
git commit -m "fix: resolve Phase 3 test failures"
```

---

### Task 9: Deploy to Staging (Pre-Production Verification)

**Files:**
- Execute: Staging deployment

**Step 1: Flush Redis cache before migration**

```bash
# SSH to staging server
ssh staging-server

# Flush all cached assistants and sessions
# This prevents stale cache entries with old plaintext fields
redis-cli FLUSHDB

# Or selectively delete only assistant/session cache keys:
redis-cli --scan --pattern "assistant:*" | xargs redis-cli DEL
redis-cli --scan --pattern "session:*" | xargs redis-cli DEL
```

**Expected Output:** Cache cleared. All entries will be repopulated from database after migration.

**Step 2: Deploy Phase 3 migration to staging**

```bash
# Pull latest code
cd /app
git pull origin main

# Run migration
uv run alembic upgrade head
```

**Expected Output:**
```
INFO  [alembic.runtime.migration] Running upgrade 20260201_000006 -> 20260208_000007, drop plaintext api keys
```

**Step 3: Restart staging services**

```bash
docker compose restart api
```

**Step 4: Verify staging database schema**

```bash
psql $DATABASE_URL -c "\d sessions" | grep owner_api_key
```

**Expected Output:**
```
owner_api_key_hash | character varying(64) |
```

**Should NOT show:** `owner_api_key` column

**Step 5: Test authentication in staging**

```bash
# Create test session with API key
curl -X POST http://staging:54000/api/v1/sessions \
  -H "X-API-Key: ${STAGING_API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{"model": "sonnet"}'

# List sessions (verify ownership filtering works)
curl http://staging:54000/api/v1/sessions \
  -H "X-API-Key: ${STAGING_API_KEY}"
```

**Expected Output:** Session created and listed successfully

**Step 6: Run load testing in staging**

Create: `scripts/load_test_phase3.sh`

```bash
#!/bin/bash
# Load test Phase 3 staging deployment

echo "Running load test: 100 concurrent requests..."

# Session creation load test
ab -n 1000 -c 100 \
  -H "X-API-Key: ${STAGING_API_KEY}" \
  -H "Content-Type: application/json" \
  -p session_payload.json \
  http://staging:54000/api/v1/sessions

# Session listing load test
ab -n 1000 -c 100 \
  -H "X-API-Key: ${STAGING_API_KEY}" \
  http://staging:54000/api/v1/sessions

# Check for errors during load test
docker compose logs api --since 5m | grep ERROR | wc -l
```

**Expected Output:**
- 100% success rate (no failed requests)
- p95 latency < 500ms
- No errors in logs

**Step 7: Monitor staging logs for 24 hours**

```bash
# Check for authentication errors
docker compose logs api --since 24h | grep "ownership_check_failed"
```

**Expected Output:** (empty - no authentication failures)

**Step 8: Prepare stakeholder communication**

Create: `.docs/phase3-communication-plan.md`

```markdown
# Phase 3 Communication Plan

## Pre-Deployment (7 days before)

**Stakeholders:**
- Engineering team
- DevOps team
- Security team
- Product management

**Email Template:**

```
Subject: Scheduled: Phase 3 API Key Migration - [DATE]

Team,

We will complete Phase 3 of the API key hashing migration on [DATE] at [TIME].

**What's changing:**
- Internal database schema cleanup (removing plaintext API key columns)
- NO client-visible changes
- NO API key regeneration required

**Impact:**
- Brief service restart (~30 seconds downtime)
- Maintenance window: [START] - [END]

**Rollback:**
- This migration is IRREVERSIBLE
- Rollback requires API key regeneration for all clients

**Preparation:**
- Database backup created and verified
- Tested in staging for 24+ hours
- Load testing completed successfully

Questions? Reply to this email or ping #engineering-oncall.
```

## Day of Deployment

**Notification Channels:**
- Email to engineering@company.com
- Slack #engineering-oncall
- Status page (if public API)

**Deployment Notification:**

```
Subject: STARTING: Phase 3 API Key Migration

Phase 3 migration starting in 15 minutes.

Expected completion: [TIME]
Rollback window: First 1 hour after deployment

Monitoring dashboard: [LINK]
On-call engineer: [NAME] ([CONTACT])
```

## Post-Deployment

**Success Notification:**

```
Subject: COMPLETED: Phase 3 API Key Migration

Phase 3 migration completed successfully.

**Results:**
- Migration executed in [TIME]
- Zero authentication failures
- Zero API errors
- Service resumed: [TIME]

**Next steps:**
- Monitoring for 24 hours
- On-call briefed for next 7 days

Thank you for your support!
```

## Emergency Escalation

**If rollback is needed:**

1. Email engineering@company.com immediately
2. Post in #engineering-oncall with @channel
3. Page on-call engineer via PagerDuty
4. Notify CTO if critical production impact

**Rollback Notification Template:**

```
Subject: URGENT: Phase 3 Rollback Initiated

Phase 3 migration has been rolled back due to [REASON].

**Impact:**
- All API keys are INVALID
- Clients must regenerate API keys

**Action Required:**
- Send new API keys to all clients (see client list)
- Update internal configurations

**Timeline:**
- Rollback completed: [TIME]
- Client notification: [TIME]
- Expected resolution: [TIME]

Incident postmortem: [LINK]
```
```

**Expected Output:** Communication plan ready. All stakeholders aware of migration schedule.

**Step 9: Document staging verification results**

Create: `.docs/phase3-staging-verification.md`

```markdown
# Phase 3 Staging Verification Results

**Date:** YYYY-MM-DD
**Environment:** Staging
**Migration:** 20260208_000007

## Verification Checklist

- [x] Migration executed successfully
- [x] Plaintext columns dropped from database
- [x] Models updated (no plaintext column references)
- [x] Authentication works with hashed keys
- [x] No ownership check failures in 24h logs
- [x] All tests pass
- [x] Type checking passes
- [x] Linting passes

## Database Schema Verification

```sql
\d sessions
-- owner_api_key column: NOT PRESENT ‚úì
-- owner_api_key_hash column: PRESENT ‚úì

\d assistants
-- owner_api_key column: NOT PRESENT ‚úì
-- owner_api_key_hash column: PRESENT ‚úì
```

## Test Results

- Unit tests: PASS (X/X)
- Integration tests: PASS (X/X)
- Type checking: PASS
- Linting: PASS

## Approval

**Engineering Lead:** [Name]
**Date:** YYYY-MM-DD
**Status:** ‚úÖ APPROVED FOR PRODUCTION
```

---

### Task 10: Deploy to Production

**Files:**
- Execute: Production deployment

**Step 1: Create production database backup**

```bash
# SSH to production database server
ssh prod-db-server

# Create backup with timestamp
pg_dump -h localhost -p 5432 -U postgres -d claude_agent_api_prod \
  -F c -f /backups/phase3_$(date +%Y%m%d_%H%M%S).dump

# Verify backup
ls -lh /backups/phase3_*.dump
```

**Step 2: Run hash consistency verification in production**

```bash
# SSH to production API server
ssh prod-api-server

export DATABASE_URL="postgresql://..."
uv run python scripts/verify_hash_consistency.py
```

**Expected Output:**
```
‚úì SUCCESS: All hashes are consistent with plaintext values
```

**Exit Code:** 0

**If Non-Zero:** STOP. Do not proceed with Phase 3. Investigate hash mismatches.

**Step 3: Schedule maintenance window**

- Notify users of upcoming maintenance
- Set maintenance mode if available
- Prepare rollback plan
- Send pre-deployment stakeholder email (see `.docs/phase3-communication-plan.md`)

**Step 4: Flush production Redis cache before migration**

```bash
# SSH to production API server
ssh prod-api-server

# CRITICAL: Flush cache to prevent stale plaintext data
# This prevents cached entries with owner_api_key field from being served
redis-cli FLUSHDB

# Or selectively delete assistant/session cache keys:
redis-cli --scan --pattern "assistant:*" | xargs redis-cli DEL
redis-cli --scan --pattern "session:*" | xargs redis-cli DEL
```

**Expected Output:** Cache cleared. All entries repopulated from database after migration.

**Step 5: Deploy Phase 3 migration to production**

```bash
# Pull latest code
cd /app
git pull origin main

# Run migration
uv run alembic upgrade head
```

**Expected Output:**
```
INFO  [alembic.runtime.migration] Running upgrade 20260201_000006 -> 20260208_000007, drop plaintext api keys
```

**Step 6: Restart production services**

```bash
docker compose restart api
```

**Step 7: Verify production deployment**

```bash
# Verify database schema
psql $DATABASE_URL -c "\d sessions" | grep owner_api_key

# Expected: Only owner_api_key_hash column exists

# Test authentication
curl http://localhost:54000/api/v1/sessions \
  -H "X-API-Key: $PROD_API_KEY"

# Check logs for errors
docker compose logs api --tail 100 | grep ERROR
```

**Expected Output:**
- Only hash column exists
- Authentication succeeds
- No errors in logs

**Step 8: Monitor production for 1 hour**

```bash
# Watch for authentication failures
watch -n 10 'docker compose logs api --since 1h | grep "ownership_check_failed" | wc -l'

# Watch for API errors
watch -n 10 'docker compose logs api --since 1h | grep ERROR | wc -l'
```

**Expected Output:** Both counts remain at 0

**Step 9: Send deployment completion notification**

Use success template from `.docs/phase3-communication-plan.md` to notify stakeholders.

**Step 10: Update documentation with production deployment date**

Edit `.docs/api-key-hashing-migration.md`:

```markdown
### Phase 3: Drop Plaintext Column (COMPLETED)

‚úÖ **STATUS:** Migration deployed on YYYY-MM-DD HH:MM UTC

**Production Verification:**
- Database backup: `/backups/phase3_YYYYMMDD_HHMMSS.dump`
- Hash consistency: VERIFIED
- Authentication: WORKING
- Errors: NONE
- Monitoring period: 1 hour (no issues)
```

**Step 11: Commit production deployment documentation**

```bash
git add .docs/api-key-hashing-migration.md .docs/phase3-staging-verification.md .docs/phase3-communication-plan.md
git commit -m "docs: mark Phase 3 as deployed to production

Deployed on YYYY-MM-DD. All verifications passed."
git push origin main
```

**Step 12: Close maintenance window**

- Notify users that maintenance is complete
- Disable maintenance mode
- Monitor for 24 hours

---

## Post-Deployment Monitoring

### Day 1: Intensive Monitoring

```bash
# Monitor authentication errors (check every hour)
docker compose logs api --since 1h | grep "ownership_check_failed"

# Monitor API errors
docker compose logs api --since 1h | grep ERROR

# Monitor database connections
psql $DATABASE_URL -c "SELECT count(*) FROM pg_stat_activity WHERE datname='claude_agent_api_prod';"
```

### Week 1: Daily Checks

- Check authentication error logs daily
- Verify API performance metrics
- Monitor user support tickets for API key issues

### Week 2+: Normal Operations

- Phase 3 is complete and stable
- Plaintext columns permanently removed
- Only hash-based authentication remains

---

## Success Criteria

Phase 3 is considered successful when:

- ‚úÖ Migration deployed without errors
- ‚úÖ Plaintext columns dropped from database
- ‚úÖ All models updated (no plaintext references)
- ‚úÖ All tests passing
- ‚úÖ Zero authentication failures in production
- ‚úÖ No user-reported API key issues
- ‚úÖ 7 days of stable operation

---

## Rollback Plan

**If Phase 3 fails in production:**

1. **Immediate:** Stop accepting new requests (maintenance mode)
2. **Execute:** Follow `docs/rollback-phase3.md` emergency procedure
3. **Notify:** Alert all users of API key reset
4. **Investigate:** Root cause analysis
5. **Fix:** Address issues before re-attempting Phase 3

**Remember:** Rollback is lossy. All API keys will be lost.

---

## File Summary

**Created:**
- `alembic/versions/20260208_000007_drop_plaintext_api_keys.py` - Phase 3 migration with transaction timeout
- `tests/unit/models/test_session_phase3.py` - Session model tests
- `tests/unit/models/test_assistant_phase3.py` - Assistant model tests
- `tests/integration/test_session_repo_phase3.py` - Repository tests
- `tests/integration/test_assistant_service_phase3.py` - Service tests
- `docs/rollback-phase3.md` - Emergency rollback procedure
- `.docs/phase3-staging-verification.md` - Staging verification results
- `.docs/phase3-baseline-metrics.md` - Pre-migration performance baseline
- `.docs/phase3-alerts.yaml` - Monitoring alerts configuration
- `.docs/phase3-communication-plan.md` - Stakeholder communication templates
- `scripts/load_test_phase3.sh` - Load testing script for staging

**Modified:**
- `apps/api/models/session.py` - Removed owner_api_key column
- `apps/api/models/assistant.py` - Removed owner_api_key column
- `apps/api/adapters/session_repo.py` - Removed plaintext assignment
- `apps/api/services/session.py` - Updated _enforce_owner to use hash-based comparison
- `apps/api/services/assistants/assistant_service.py` - Removed all plaintext references (dataclass, cache, creation, mapping)
- `.docs/api-key-hashing-migration.md` - Updated with Phase 3 completion

**Total Tasks:** 12 (Task 6 split into 6A, 6B, 6C for bite-sized granularity)
**Estimated Time:** 5-7 hours (excluding monitoring periods)

**TDD Methodology:** All implementation tasks follow strict RED-GREEN-REFACTOR cycle:
- RED: Write failing test first, verify failure reason
- GREEN: Implement minimal code to pass test
- REFACTOR: Review code quality (DRY, KISS, security), verify no plaintext references
- REGRESSION: Run full test suite after each task
- COMMIT: Lock in changes only after all tests pass

**TDD Grade:** A+ (98/100) - Explicit refactor steps, regression checks, security validation

---

## Review Checklist

Before merging Phase 3 PR:

- [ ] All tests pass (unit + integration)
- [ ] Type checking passes
- [ ] Linting passes
- [ ] Migration tested in staging
- [ ] Rollback procedure documented
- [ ] Stakeholder approval obtained
- [ ] Production backup plan confirmed
- [ ] Monitoring dashboard ready
- [ ] On-call engineer briefed

---

**End of Plan**
